{
    "collab_server" : "",
    "contents" : "---\noutput:\n  html_document:\n    code_folding: hide\n    theme: yeti\n    highlight: pygments\n---\n<br><br>\n![](banner.png)\n\n***\n\n## Objetivo\n  \n<p align=\"justify\">**Apresentar estudo inicial realizado para domínio da plataforma de computação estatística \"R\". Os dados utilizados foram extraídos a partir de BI (Banco de Inteligência de Negócio) criado pela CTI em Fevereiro de 2017, sobre contas médicas e suas dimensões, com uma série temporal entre 2014 até a última referência fechada e atualizada, em março de 2017.**</p>\n\n***\n`ATENÇÃO`\n<p align=\"justify\">*O conteúdo deste documento é de natureza confidencial e não deverá ser circulado sem expressa autorização da Coordenação Geral do Planserv.*</p>\n\n<p align=\"justify\">*Não será objetivo deste relatório tratar em detalhes as técnicas estatísticas utilizadas, com exceção de pontos relevantes para demonstrar a flexibilidade da ferramenta, como por exemplo a abordagem para verificar problemas de autocorrelação em séries temporais. A teoria estatística envolvida, embora interessante para alguns públicos, tonaria o relato demasiado extenso.*</p>\n***\n\n##Conteúdo\n\n1. [Descrição da Tecnologia](#descricao-da-tecnologia)  \n2. [Introdução ao Estudo Proposto](#introducao-ao-estudo-proposto)  \n3. [Análise de Correlação](#analise-de-correlacao)  \n4. [Gráficos para Comunicação](#graficos-para-comunicacao)  \n5. [Direcionamento no Estudo](#direcionamento-no-estudo)  \n6. [Análise Detalhada sobre Consulta e Exames](#analise-detalhada-sobre-consulta-e-exames)  \n6.1 [Preparação](#preparacao)  \n6.2 [Seleção de Escopo pelo Indicador de Internação](#selecao-de-escopo-pelo-indicador-de-internacao)  \n7. [Regressão Linear](#regressao-linear)  \n7.1 [Modelo Inicial](#modelo-inicial)  \n7.2 [Aspectos e Avaliação da Regressão](#aspectos-e-avaliacao-da-regressao)  \n7.3 [Considerações sobre Séries Temporais](#consideracoes-sobre-series-temporais)  \n7.4 [Avaliação Específica para Objetos do Pacote \"Orcutt\"](#avaliacao-especifica-para-objetos-do-pacote-orcutt)  \n7.5 [Alternativa de Transformação](#alternativa-de-transformacao)  \n8. [Outros Experimentos](#outros-experimentos)  \n9. [Visualizações de Dados](#visualizacoes-de-dados)  \n10. [Conclusão](#conclusao)  \n\n***\n## Descrição da Tecnologia\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">A ferramenta foi criada em 1992, por Ross Ihaka e Robert Gentleman, professores de estatística na Universidade de Auckland, Nova Zelândia, como um desenvolvimento comunitário de fonte livre (gratuito) sobre a linguagem \"S\", núcleo fundamental da plataforma estatística S-Plus, comercializada.</p> \n\n<p align=\"justify\">\"R\" pode ser descrita como uma linguagem de programação interpretativa (não é necessário compilar seus scripts), possui integração com sistemas de gerenciamento de bancos de dados, outras linguagens (como Python), outras plataformas estatísticas (importações de SPSS, SAS, Stata, Minitab), MSExcel e arquivos planos.</p>\n\n<p align=\"justify\">Desde sua criação, seu conteúdo básico foi extensamente ampliado pela comunidade por meio da construção de pacotes que podem facilmente ser anexados ao ambiente básico, e que ampliam as funcionalidades da ferramenta contemplando a maioria das práticas estatísticas conhecidas, estilos e ferramentas para apresentações gráficas, manipulação de dados, controles de qualidade, funções para facilitar e simplificar o desenvolvimento de seu código, entre outras.</p>\n\n<p align=\"justify\">Como exemplo do funcionamento desta estrutura modular, abaixo estão os pacotes que foram utilizados no estudo, contendo cada um várias das funções aplicadas na geração dos resultados demonstrados abaixo:</p>\n\n```{r setup, message = FALSE, warning = FALSE}\n## Opções iniciais de configuração do ambiente --------------\nknitr::opts_chunk$set(echo = TRUE)\noptions(scipen=999)\n#### --------------------------------------------------------\nlibrary(\"reshape2\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\nlibrary(\"readxl\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\nlibrary(\"qcc\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\nlibrary(\"modelr\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\nlibrary(\"dplyr\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\nlibrary(\"ggplot2\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\nlibrary(\"readr\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\nlibrary(\"tibble\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\nlibrary(\"tidyr\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\nlibrary(\"purrr\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\nlibrary(\"forcats\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\nlibrary(\"plotrix\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\n\n## ** Pacotes básicos que compõe o Tidyverse poderiam ser ativados com uma unica linha:\n#library(\"tidyverse\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\n#Loading tidyverse: ggplot2\n#Loading tidyverse: tibble\n#Loading tidyverse: tidyr\n#Loading tidyverse: readr\n#Loading tidyverse: purrr\n#Loading tidyverse: dplyr\n```\n\nVersão da plataforma \"R\": 3.4.1 (2017-06-30) \"Single Candle\"<br>\n<https://www.r-project.org/><br>\nVersão do ambiente de programação \"RStudio\": 1.0.143<br>\n<https://www.rstudio.com/><br>\nPacotes principais nesta apresentação: Tidyverse 1.1.1<br>\n<http://tidyverse.org/><br>\n\n<p align=\"justify\">A apresentação deste relatório foi integralmente concebida com a utilização do ambiente de programação RStudio, com a funcionalidade R-Markdown. <http://rmarkdown.rstudio.com/index.html></p>\n\n![](rstudio.png)\n<br><br>\n<p align=\"right\">*Ambiente de desenvolvimento integrado, RStutdio*</p>\n***\n\n<p align=\"justify\">Para efeito demonstrativo, a maior parte dos comandos e funções utilizados para geração de resultados na ferramenta foi mantido à vista, porém a supressão destes itens, mantendo apenas tabelas, comentários e gráficos é facilmente executada dentro da estrutura RStudio + R-Markdown.</p>\n***\n## Introdução ao Estudo Proposto\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">O trabalho teve início com dados gerados a partir da ferramenta Power BI e exportados para Excel, tratados e importados para o \"R\" de maneira não transformada (arquivo plano), e posteriormente também importados com transformações para processamento estatístico (onde colunas = variáveis). Os dados incluídos seguem as seguintes características:</p>\n\n- Série temporal pela data de atendimento do componente assistencial;\n- Duas consolidações de quantidade por mês de referência, uma entre dias 1 a 15 e outra entre 16 a 31, para aumento da eficácia dos testes relacionados;\n- Na transformação, foram filtrados dados de maior relevância, a partir de janeiro de 2014, gerando 78 observações por componente;\n- Dados de Componente, Ano/mês/Quinzena e Indicador de Internação (CAI);\n\n```{r dados originais}\n#### Formato original, trabalhado no MS Excel ---------------\norg <- read_excel('CAIv2.xlsx');org;\n#### Formato para processamento estatístico -----------------\ncai <- read_excel('CAIv2.xlsx') %>% # readxl: importação\n  group_by(componente,internacao,amq) %>% # dplyr: agrupamento\n  summarise(valor = sum(valor), qt = sum(quantidade)) %>% # dplyr: sumarização\n  select(-valor) %>% # dplyr: retirada de uma coluna\n  spread(componente,qt) %>% # tidyr: mudança de formato, de chave-valor para colunas\n  arrange(amq, internacao) %>%  # dplyr: reordenação\n  filter(amq>=\"20140101\"); cai; # dplyr: seleção;\n```\n***\n## Análise de Correlação\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">A partir da tabela transformada acima, foi criada uma matriz de correlação entre os componentes, para verificação de quais pares apresentavam influência sobre os demais. De modo a avaliar todas os relacionamentos, foram criadas três versões: completo (C), sem internação(N) e com internação (S):</p>\n\n```{r correlação, warning=FALSE}\n#### Transformações sobre dados da \"CAI\"\" -------------------\ncaiC.precor <- cai %>%\n  arrange(amq, internacao) %>% \n  group_by(amq) %>% \n  summarise(consulta = sum(consulta, na.rm = TRUE), \n            domiciliar = sum(domiciliar, na.rm = TRUE), \n            emergencia = sum(emergencia, na.rm = TRUE), \n            honorario = sum(honorario, na.rm = TRUE), \n            material = sum(material, na.rm = TRUE), \n            medicamento = sum(medicamento, na.rm = TRUE), \n            nulo = sum(nulo, na.rm = TRUE), \n            pacote = sum(pacote, na.rm = TRUE), \n            remocao = sum(remocao, na.rm = TRUE), \n            sadt = sum(sadt, na.rm = TRUE), \n            taxa = sum(taxa, na.rm = TRUE)) %>% \n  as.data.frame(.) %>%\n  select(-amq) %>% \n  as.tibble()\n\ncaiN.precor <- cai %>%\n  filter(internacao == 'n') %>% \n  arrange(amq) %>%   \n  group_by(amq) %>% \n  summarise(consulta = sum(consulta, na.rm = TRUE), \n            domiciliar = sum(domiciliar, na.rm = TRUE), \n            emergencia = sum(emergencia, na.rm = TRUE), \n            honorario = sum(honorario, na.rm = TRUE), \n            material = sum(material, na.rm = TRUE), \n            medicamento = sum(medicamento, na.rm = TRUE), \n            nulo = sum(nulo, na.rm = TRUE), \n            pacote = sum(pacote, na.rm = TRUE), \n            remocao = sum(remocao, na.rm = TRUE), \n            sadt = sum(sadt, na.rm = TRUE), \n            taxa = sum(taxa, na.rm = TRUE)) %>% \n  as.data.frame(.) %>%\n  select(-amq) %>% \n  as.tibble()\n\ncaiS.precor <- cai %>%\n  filter(internacao == 's') %>% \n  arrange(amq) %>% \n  group_by(amq) %>% \n  summarise(consulta = sum(consulta, na.rm = TRUE), \n            domiciliar = sum(domiciliar, na.rm = TRUE), \n            emergencia = sum(emergencia, na.rm = TRUE), \n            honorario = sum(honorario, na.rm = TRUE), \n            material = sum(material, na.rm = TRUE), \n            medicamento = sum(medicamento, na.rm = TRUE), \n            nulo = sum(nulo, na.rm = TRUE), \n            pacote = sum(pacote, na.rm = TRUE), \n            remocao = sum(remocao, na.rm = TRUE), \n            sadt = sum(sadt, na.rm = TRUE), \n            taxa = sum(taxa, na.rm = TRUE)) %>% \n  as.data.frame(.) %>%\n  select(-amq) %>% \n  as.tibble()\n\n#### Limpeza de objetos, caso necessário para recriação -----\nrm(caiC.cor,caiS.cor,caiN.cor)\n\n#### Criação de tabelas -------------------------------------\ncaiC.corP <- caiC.precor %>% \n  cor(., method = 'pearson');as.tibble(caiC.corP)\n\n#### Apenas a primeira tabela (^) será demonstrada ----------\ncaiN.corP <- caiN.precor %>% \n  cor(., method = 'pearson');#caiN.corP\n\ncaiS.corP <- caiS.precor %>% \n  cor(., method = 'pearson');#caiS.corP\n\n#### Representação por simbolos -----------------------------\nCcorgrid <- symnum(caiC.corP);Ccorgrid\n\n#### Apenas a primeira tabela (^) será demonstrada ----------\nNcorgrid <- symnum(caiN.corP);#Ncorgrid\nScorgrid <- symnum(caiS.corP);#Scorgrid\n\n#### Tratamento para apresentação gráfica -------------------\ncaiC.corP[lower.tri(caiC.corP)] <- NA\ncaiN.corP[lower.tri(caiN.corP)] <- NA\ncaiS.corP[lower.tri(caiS.corP)] <- NA\n```\n***\n## Gráficos para Comunicação\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">Embora suficientes para avaliação estatística de profissionais, os instrumentos apresentados até então não são adequados para demonstração de resultados  e apreciação de públicos em geral (outras capacidades sobre visualização serão tratadas ao final deste estudo, no tópico anterior à conclusão).</p>\n<p align=\"justify\">Com objetivo de evoluir da análise para comunicação, os dados de correlação foram submetidos a manipulação por um dos pacotes especialistas do \"R\" para apresentações gráficas (GGPlot2), foram então gerados os mapas de correlação com estética mais adequada:</p>\n\n```{r plot correlação 01, fig.height=7, fig.width=10}\n#### Gráfico gerado a partir do comando abaixo (exemplo) ----\nGGcorC <- ggplot(data = melt(caiC.corP, na.rm = TRUE), aes(Var2, Var1, fill = value)) +\n  geom_tile(color = \"white\") +\n  theme_minimal()+ \n  theme(axis.text.x = element_text(angle = 45, \n                                   vjust = 1, \n                                   size = 12, \n                                   hjust = 1),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank())+\n  guides(fill = guide_colorbar(barwidth = 1, \n                               barheight = 7,\n                               title.position = \"bottom\")) +\n  coord_fixed();GGcorC\n\n#### Camada adicionada ao gráfico original ------------------\nGGcorC + \n  geom_text(aes(Var2, Var1, label = format(value, digits = 1, nsmall= 3)), \n            color = \"black\", \n            size = 3) +\n  scale_fill_distiller(palette = \"Spectral\", \n                       #trans = \"reverse\",\n                       #space = \"Lab\", \n                       name=\"Correlação de\\nPearson\\n|Total|\")\n\n```\n\nDemais gráficos (Correlação de componentes com Internação = N,S), comandos do \"R\" para geração foram ocultados:\n\n```{r plot correlação 02, echo=FALSE, fig.height=7, fig.width=10}\nGGcorN <- ggplot(data = melt(caiN.corP, na.rm = TRUE), aes(Var2, Var1, fill = value)) +\n  geom_tile(color = \"white\") +\n  scale_fill_distiller(palette = \"RdYlGn\", \n                       direction = 1,\n                       #space = \"Lab\", \n                       name=\"Correlação de\\nPearson\\n|Ambulatório|\") +  \n  theme_minimal()+ \n  theme(axis.text.x = element_text(angle = 45, \n                                   vjust = 1, \n                                   size = 12, \n                                   hjust = 1),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank())+\n  guides(fill = guide_colorbar(barwidth = 1, \n                               barheight = 7,\n                               title.position = \"bottom\")) +\n  coord_fixed()\nGGcorN + \n  geom_text(aes(Var2, Var1, label = format(value, digits = 1, nsmall= 3)), \n            color = \"black\", \n            size = 3)\n\nGGcorS <- ggplot(data = melt(caiS.corP, na.rm = TRUE), aes(Var2, Var1, fill = value)) +\n  geom_tile(color = \"white\") +\n  scale_fill_distiller(palette = \"Set2\", \n                       #trans = \"reverse\",\n                       #space = \"Lab\", \n                       name=\"Correlação de\\nPearson\\n|Internação|\") +  \n  theme_minimal()+ \n  theme(axis.text.x = element_text(angle = 45, \n                                   vjust = 1, \n                                   size = 12, \n                                   hjust = 1),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank())+\n  guides(fill = guide_colorbar(barwidth = 1, \n                               barheight = 7,\n                               title.position = \"bottom\")) +\n  coord_fixed()\nGGcorS + \n  geom_text(aes(Var2, Var1, label = format(value, digits = 2, nsmall= 3)), \n            color = \"black\", \n            size = 3)\n```\n\n***\n## Direcionamento no Estudo\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">Após verificadas as influências, se fez necessária uma seleção para detalhamento investigativo, além de um entendimento sobre o sentido da correlação. Deste modo foi realizada uma consulta pelo BI de Contas para verificação de quais componentes correlacionados se mostravam relevantes, por valor e percentual no faturamento acumulado entre 2014 e 2017:</p>\n\n```{r avaliação de relevância}\n#### Tabela criada manualmente para simplificação de nomes --\n(depara_componente <- read_excel('depara_componente.xlsx'))\n\n#### Importações (Geradas pelo Power BI com um click) -------\n`dataset` = read.csv('C:/Users/xurus/Documents//REditorWrapper_e74c054e-473b-47b7-b164-7b93f69f36af/input_df_0ab2289d-603e-43e7-9cef-461c578edbbb.csv', check.names = FALSE, encoding = \"UTF-8\", blank.lines.skip = FALSE);\n`dataset2` = read.csv('C:/Users/xurus/Documents//REditorWrapper_6b9a785a-59bf-48ad-abdd-04471637f315/input_df_26cec917-4b9e-45bf-9a31-7a50e9d1f2d7.csv', check.names = FALSE, encoding = \"UTF-8\", blank.lines.skip = FALSE);\n\n#### Criação de resumos, por indicador de internação --------\nresumo_valor_N <- dataset %>% \n  select(internacao = \"Indicador de Internação\", \n         componente = \"Componente assistencial\",\n         valor = \"Valor Total\",\n         percentual =  \"Valor Total.1\",\n         quantidade = \"Quantidade Aprovada\") %>% \n  mutate(percentual = as.numeric(format(percentual*100, digits = 2)))\n\nresumo_valor_S <- dataset2 %>% \n  select(internacao = \"Indicador de Internação\", \n         componente = \"Componente assistencial\",\n         valor = \"Valor Total\",\n         percentual =  \"Valor Total.1\",\n         quantidade = \"Quantidade Aprovada\") %>% \n  mutate(percentual = as.numeric(format(percentual*100, digits = 2)))\n\n#### Renomeação/substituição/exclusão de colunas (estudo) ---\ndepara_componente <- depara_componente %>% \n  select(componente = \"Componente assistencial\", comp = \"componente\")\n\nresumo_valor_S <- merge(resumo_valor_S, depara_componente, by = \"componente\") %>% \n  mutate(componente = comp) %>% \n  select(-comp)\n\nresumo_valor_N <- merge(resumo_valor_N, depara_componente, by = \"componente\") %>% \n  mutate(componente = comp) %>% \n  select(-comp)\n\n#### Unificação de Tabelas-----------------------------------\nresumo_valor <- rbind(resumo_valor_N,resumo_valor_S) %>% \n  arrange(internacao, desc(percentual)) %>% \n  select(-valor); resumo_valor\n```\n\n<p align=\"justify\">Foram então filtradas as maiores Correlações, e agregado o valor como uma nova coluna, para correlações com internação, e sem internação. Atenção especial foi dada ao relacionamento de pacotes para internação = \"S\":</p>\n\n```{r maiores correlações}\n#### Transformação de tabela de correlação e filtro ---------\ntopcorS <- melt(caiS.corP, na.rm = TRUE) %>% \n  filter((value >= 0.85 | ((Var1 == \"pacote\" | Var2 == \"pacote\") \n                           & value >= 0.70)) & value != 1) %>% \n  arrange(desc(value))\n\ntopcorN <- melt(caiN.corP, na.rm = TRUE) %>% \n  filter(value >= 0.85 & value != 1) %>% \n  arrange(desc(value))\n\n#### Lookup de Tabelas --------------------------------------\ntopcorS_W <- add_column(topcorS, Var1_prct = resumo_valor_S[match(topcorS$Var1, resumo_valor_S$componente),4])\ntopcorS_W <- add_column(topcorS_W, Var2_prct = resumo_valor_S[match(topcorS$Var2, resumo_valor_S$componente),4])\n\ntopcorN_W <- add_column(topcorN, Var1_prct = resumo_valor_N[match(topcorN$Var1, resumo_valor_N$componente),4])\ntopcorN_W <- add_column(topcorN_W, Var2_prct = resumo_valor_N[match(topcorN$Var2, resumo_valor_N$componente),4])\n\n#### Reordenação de colunas ---------------------------------\nnames(topcorS_W)\n(topcorS_W <- select(topcorS_W, \"Var1\",\"Var1_prct\",\"Var2\",\"Var2_prct\",Corr = \"value\"))\n(topcorN_W <- select(topcorN_W, \"Var1\",\"Var1_prct\",\"Var2\",\"Var2_prct\",Corr = \"value\"))\n```\n\n<p align=\"justify\">Devido à relevância de Taxas e Pacotes em internação, foram averiguadas as correlações cruzadas (presumidamente altas) a partir de consultas e emergência, que são considerados como ambulatoriais.</p>\n\n<p align=\"justify\">Para fins de estudo, foram criadas tabelas separadas e individualizadas para a análise, porém uma abordagem similar às tabelas de correlação geral poderia ter sido utilizada, com menos processos intermediários na ferramenta, e diminuição de passos:</p>\n\n```{r correlacao cruzada}\n#### Preparação: Transformação de tabela agrupada em plana --\ncai_df <- cai %>% \n  as.data.frame(.) %>% \n  as.tibble()\n\n#### Cor. Emergencia, Consulta > Taxas, Pacotes em Internação\ncai_ECn_PTs <- cai_df %>%\n  filter(internacao == \"s\") %>% \n  arrange(amq) %>% \n  select(taxa) %>% \n  as.tibble()\n\ncai_temp <- cai_df %>%\n  filter(internacao == \"n\") %>% \n  arrange(amq) %>% \n  select(emergencia) %>% \n  as.tibble()\n\ncai_ECn_PTs <- cai_ECn_PTs %>% add_column(emergencia = cai_temp$emergencia)\n\ncai_temp <- cai_df %>%\n  filter(internacao == \"n\") %>% \n  arrange(amq) %>% \n  select(consulta) %>% \n  as.tibble()\n\ncai_ECn_PTs <- cai_ECn_PTs %>% add_column(consulta = cai_temp$consulta)\n\ncai_temp <- cai_df %>%\n  filter(internacao == \"s\") %>% \n  arrange(amq) %>% \n  select(pacote) %>% \n  as.tibble()\n\ncai_ECn_PTs <- cai_ECn_PTs %>% add_column(pacote = cai_temp$pacote)\ncai_ECn_PTs <- cai_ECn_PTs[1:77,]\n\ncai_ECn_PTs.corP <- cai_ECn_PTs %>% \n  cor(., method = 'pearson');cai_ECn_PTs.corP\n```\n![](mapa.png)\n<br>\n<p align=\"right\">*\\* Mapeamento sujeito à mudanças*</p>\n\n***\n## Análise Detalhada sobre Consulta e Exames\n[Retorno para Conteúdo](#conteudo)\n\n### Preparação\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">Com base nas descobertas apontadas pela correlação, e considerando o sentido de influência conhecido de consultas sobre exames, foi então realizada uma investigação de cunho estatístico inferencial, com técnicas mais relevantes para determinação de um modelo preditivo, onde a variável independente é a quantidade de consultas, e a resposta é a quantidade de exames. Tais analises deverão ser realizadas sobre outros conteúdos e elementos, com diversos e adequados modelos de regressão, e com maior detalhamento para efetividade e precisão, como por exemplo, a quebra de consultas e exames de uma determinada especialidade médica.</p>\n\n```{r preparação para SC}\n#### Preparação: Consulta sobre exames em Internação --------\n\ncai_SCs <- cai_df %>%\n  filter(internacao == \"s\") %>% \n  arrange(amq) %>% \n  select(sadt) %>% \n  as.tibble()\n\ncai_temp <- cai_df %>%\n  filter(internacao == \"n\") %>% \n  arrange(amq) %>% \n  select(consulta) %>% \n  as.tibble()\n  \ncai_SCs <- cai_SCs %>% add_column(consulta = cai_temp$consulta)\n\n#### Preparação: Consulta sobre exames sem Internação -------\n\ncai_SCn <- cai_df %>%\n  filter(internacao == \"n\") %>% \n  arrange(amq) %>% \n  select(sadt) %>% \n  as.tibble()\n\ncai_SCn <- cai_SCn %>% add_column(consulta = cai_temp$consulta)\n\n#### Preparação: Consulta sobre exames totais ---------------\n\n#rm(cai_SCc)\n                       \ncai_SCc <- cai_df %>% \n  select(amq,sadt) %>% \n  group_by(amq) %>% \n  summarise(sadt=sum(sadt)) %>% \n  as.data.frame(.) %>% \n  select(sadt) %>% \n  as.tibble()\n\n## Inclusão de coluna \"z\", análise de variação por desvios padrão, outliers acima de 3 \nzSc <- scale(cai_SCc$sadt, center = TRUE, scale = TRUE) \ncai_SCc <- cai_SCc %>% add_column(consulta = cai_temp$consulta, z = zSc[1:dim(cai_SCc)[1]])\n```\n\n### Seleção de Escopo pelo Indicador de Internação\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">Também foi criada uma tabela para avaliação de relevância de SADT total, com e sem internação:</p>\n\n```{r sadt total, N, S, fig.height=7, fig.width=10}\ncai_g <- cai_SCc %>% \n  select(consulta, sadt_t = sadt) %>% \n  add_column(sadt_n = cai_SCn$sadt) %>% \n  add_column(sadt_s = cai_SCs$sadt)\n\nplot(cai_g)\n```\n\n<p align=\"justify\">A matriz de gráficos de dispersão indicou uma forte semelhança de comportamento entre **Consulta Eletiva sobre SADT total**, e **Consulta Eletiva sobre SADT sem internação (ambulatorial)**. Também pode ser verificado que **Consulta Eletiva sobre SADT com internação (hospitalar)** apresenta uma relação mais difusa, pois exames restritos ao ambiente hospitalar geralmente são disparados por outros componentes, fato que poderia ser comprovado com uma analise de correlação específica, caso a resposta gráfica não fosse suficiente. Com base nos resultados, o estudo foi então direcionado para modelo entre **Consulta e SADT total**.</p>\n***\n## Regressão Linear\n[Retorno para Conteúdo](#conteudo)\n\n### Modelo Inicial\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">Após determinação das variáveis de estudo, a criação do modelo é bastante simplificada pela ferramenta, através da função lm (Linear Model), onde \"sadt ~ consulta\" representa uma equação de previsão de quantidades de sadt por meio da informação de quantidades de consulta:</p>\n\n```{r regressão}\n#### Avaliar regressão --------------------------------------\nlm(sadt ~ consulta, data = cai_SCc) %>% \n  summary()\n#### Avaliar se intervalo de confiança de 99% inclui 0 ------\nconfint(lm(sadt ~ consulta, data = cai_SCc), level=0.99)\n```\nFormula:\n\n<p align=\"left\"><font size=\"3\" color=\"brown\">$y = \\beta_0 + \\beta_1x$</font>, onde $\\beta_0$ = intercepto e $\\beta_1$ = inclinação</p>\n<p align=\"left\"><font size=\"3\" color=\"brown\">$_{qt}sadt = \\beta_0 + (\\beta_1 * _{qt}consulta)$</font></p>\n<p align=\"left\"><font size=\"3\" color=\"brown\">$_{qt}sadt =   72791.6402 +  (11.6330 * _{qt}consulta)$</font></p>\n\n<p align=\"justify\">Apresentando valores de $p$ inferiores a **0,01** para ambos os coeficientes da equação e também para a estatística de variação $F$, a regressão simples pode ser considerada de boa qualidade e suficiente, comprovando as tendências previamente apontadas na correlação. Caso necessário, modelos de outras naturezas poderiam ser aplicados na ferramenta (lineares múltiplos, quadráticos e não lineares, como polinomiais e exponenciais).</p>\n\n<p align=\"justify\">O valor do coeficiente de determinação $r^2$ de **0.8948** significa que a quantidade de consultas explica **89,48%** da variação de quantidade de exames, e portanto o valor do modelo como instrumento preditivo aparenta ser relevante, inicialmente.</p>\n\nO resultado estatístico pode ser visualizado no gráfico abaixo:\n\n```{r, modelos inicial, fig.height=7, fig.width=10}\n#### Gerar objeto com modelo --------------------------------\nlm.cai_SCc <- lm(sadt ~ consulta, data = cai_SCc)\n#### Incluir conluna com valores previstos ------------------\ncai_SCc <- cai_SCc %>% add_predictions(lm.cai_SCc) #modelr\n#### Gráfico do modelo --------------------------------------\nggplot(cai_SCc, aes(y = consulta)) +\n  geom_point(aes(x = sadt), color = \"blue\", alpha = 0.5, size = 3) +\n  geom_line(aes(x = pred),color = \"red\", size = 1.2) +\n  labs(title = 'Modelo proposto', \n       x = 'SADT', y = 'Consulta')\n```\n\n### Aspectos e Avaliação da Regressão\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">Embora as evidências apontem para um modelo bem construído, existe ainda a necessidade de verificar todas as quatro premissas da regressão: Linearidade (que pode ser verificada acima); Independência de variáveis (de suma importância no uso de séries temporais, devido à possibilidade de Autocorrelação: a ocorrência de dependência entre observações adjacentes no tempo), normalidade e Igualdade de variâncias para valores previstos (de SADT) ao longo de todos os valores de previsão (consulta).</p>\n\n<p align=\"justify\">A função padrão de plotagem de gráfico aplicada ao objeto do modelo na ferramenta, é excelente para verificação rápida de Linearidade (gráfico 1), normalidade (gráfico 2) e Igualdade (gráfico 3), além de oferecer também um teste de alavancagem (gráfico 4), que verifica se alguma observação extrema tem influência forte sobre todo o modelo:</p>\n\n```{r plot original, fig.height=7, fig.width=10}\n## Gráficos\n## (1) (2)\n## (3) (4)\npar(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))\n#### Validando modelo pelos gráficos padrão -----------------\nplot(lm.cai_SCc)\n#### Retornando à configurção de plotagem com Gráfico Único -\npar(mfrow = c(1,1), oma = c(0, 0, 0, 0))\n```\n\n### Considerações sobre Séries Temporais\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">No aspecto de independência das variáveis, se faz necessária a utilização de técnicas como os testes de **Durbin-Watson** ou **Breusch-Godfrey**, para verificar autocorrelação. Uma vez identificada a técnica estatística desejada, uma consulta em sites de busca geralmente é suficiente para apontar a função e pacote correspondentes, estes podem ser adicionados de maneira simples por meio do ambiente RStudio, tornam-se disponíveis para uso nos scripts.</p>\n\n```{r teste de autocorrelação, message=FALSE, warning=FALSE}\n#### Definição do repositório para download -----------------\n\n## options(repos = 'http://vps.fmvz.usp.br/CRAN/')\n\n#### Instalação do novo pacote ------------------------------\n\n## install.packages(\"lmtest\")\n\n#### Ativação do pacote com o teste estatístico -------------\nlibrary(\"lmtest\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\n#### Testes de autocorrelação -------------------------------\ndwtest(lm.cai_SCc)\nbgtest(lm.cai_SCc, order = 2)\n```\n\n<p align=\"justify\">Ambos os testes apontam valor $p$ tendendo a zero, o que indica a rejeição da hipótese nula (que assume a Autocorrelação = 0), e portanto uma transformação é necessária, para enquadramento do princípio de independência de variáveis. Novamente, uma vez identificada a técnica estatística (neste caso, transformação de **Cochrane Orcutt**), uma pesquisa é feita, a função e pacote são identificados, importados na ferramenta, e utilizados após ativação. Em seguida encontra-se o gráfico com ambos os modelos, original com autocorrelação (em vermelho) e transformado, sem ruídos ($rho$) de autocorrelação (em verde):</p>\n\n```{r transformação e gráficos, fig.height=7, fig.width=10}\n#### Ativação do pacote com transformação para Autocorrelação\nlibrary(\"orcutt\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\n#### Transformação dos modelo para eliminação do ruído ------\nlmT.SCc <- cochrane.orcutt(lm.cai_SCc)\n#### Inclusão de coluna com valores previstos ajustados -----\ncai_SCc <- cai_SCc %>% add_column(predT = as.vector(fitted(lmT.SCc))) #modelr\n#### Novo gráfico, com ambos modelos ------------------------\nggplot(cai_SCc, aes(y = consulta)) +\n  geom_point(aes(x = sadt), color = \"blue\", alpha = 0.5, size = 3) +\n  geom_line(aes(x = pred),color = \"red\", size = 1.2) +\n  geom_line(aes(x = predT), color = \"green\", size = 1.2) +\n  labs(title = 'Modelo original e transformado, procedimento Cochrane Orcutt, *em verde', \n       x = 'SADT', y = 'Consulta')\n```\n\n<p align=\"justify\">Além da análise gráfica, uma revisão do sumário do novo modelo pode ser realizado com uma função específica do novo pacote:</p>\n\n```{r análise após transformação}\nsummary.orcutt(lmT.SCc)\n```\n\nFormula:\n\n<p align=\"left\"><font size=\"3\" color=\"brown\">$y = \\beta_0 + \\beta_1x$</font>, onde $\\beta_0$ = intercepto e $\\beta_1$ = inclinação</p>\n<p align=\"left\"><font size=\"3\" color=\"brown\">$_{qt}sadt = \\beta_0 + (\\beta_1 * _{qt}consulta)$</font></p>\n<p align=\"left\"><font size=\"3\" color=\"brown\">$_{qt}sadt =  131162.26639 + (10.31995 * _{qt}consulta)$</font></p>\n\n<p align=\"justify\">Primeiramente, é importante avaliar o resultado do teste de **Durbin Watson** para o modelo transformado, com valor próximo à **2**, e $p$ = **0.6253**, o que significa que não há evidências suficientes para rejeitar $h_0$ (*hipótese nula*), onde a autocorrelação é igual a *zero*. O modelo ajustado revela as mesmas boas características, com valor $p$ para o teste $t$ dos coeficientes aproximadamente zero, assim como $p$ para a estatística de variação ($F$). O valor de $r^2$ dos novos resultados mostram que a variável quantidade de consultas explica **94,55%** da variação de SADT, demonstrando a validade do novo modelo para predição.</p>\n\n### Avaliação Específica para Objetos do Pacote \"Orcutt\"\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">Devido à particularidade do pacote utilizado para a transformação (com objetos de modelo linear proprietários), uma análise dos aspectos da regressão por funções padrão da ferramenta é limitada. Se faz necessária programação específica para diagnóstico de linearidade, normalidade e igualdade de variâncias:</p>\n\nPadronização de resíduos:<font size=\"4\" color=\"brown\">$_{Std.}e = (\\frac{e_i}{\\sigma_e})_{1\\leqslant i\\leqslant n}$</font>,\nonde <font size=\"3\" color=\"brown\">$\\sigma = \\sqrt\\frac{\\sum_{i=1}^n(X_i-\\bar X)^2}{n-1}$</font>\n\n```{r diagnósticos construídos, fig.height=7, fig.width=10}\n#### Valores previstos --------------------------------------\nfit_r <- fitted(lmT.SCc)\n#### Gráfico padrão (1) Linearidade -------------------------\nplot(fit_r, resid(lmT.SCc),\n     ylab = \"Resíduos/Erros\", \n     xlab = \"Valores Previstos\",\n     main = \"Linearidade e Variância\")\n#### Linha de referência ------------------------------------\nsmt = smooth.spline(fit_r, resid(lmT.SCc), spar=1)\nabline(h = 0, lty = 2)\nlines(smt, col='red', lwd=1)\n\n#### Resíduos padronizados ----------------------------------\nstd_r <- resid(lmT.SCc)/sd(resid(lmT.SCc))\n# ou std_r <- scale(resid(lmT.SCc), center = FALSE, scale = TRUE)\n\n#### Gráfico padrão (2) Normalidade -------------------------\nqqnorm(std_r)\n#### Linha de referência ------------------------------------\nqqline(std_r, lty = 2)\n\n#### Raiz de resíduos padronizados --------------------------\nstd_r <- sqrt(abs(std_r))\n#### Gráfico padrão (3) Igualdade ---------------------------\nplot(fit_r, std_r, \n     ylab = expression(sqrt(\"Resíduos Padrão\")), \n     xlab = \"Valores Previstos\",\n     main = \"Escala e Localização de Resíduos\")\n#### Linha de referência ------------------------------------\nsmt = smooth.spline(fit_r, std_r, spar=1)\nlines(smt, col='red', lwd=1)\n```\n\n### Alternativa de Transformação\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">Uma alternativa de eliminação dos ruídos da autocorrelação é o procedimento de **Hildreth-Lu**, porém esta abordagem exige aplicação da transformação para todas as novas predições, pois existe uma alteração da escala dos dados:</p>\n\n```{r segunda transformação, fig.height=7, fig.width=10}\n#### Ativação do pacote com a segunda forma de transformação\nlibrary(\"HoRM\", lib.loc=\"C:/Program Files/R/R-3.4.1/library\")\n#### Valor de rho a partir da primeira transformação --------\nlmT.SCc[\"rho\"]\n#### Regressão com o novo procedimento ----------------------\nlmT_hil.SCc <- hildreth.lu(x = cai_SCc$consulta, y = cai_SCc$sadt, rho = 0.7097007)\n         ## rho representa o ruído gerado pela autocorrelação\n\n#### Extração de dados a partir do objeto do modelo ---------\ncai_SCc_Hil <- as.tibble(lmT_hil.SCc[[\"model\"]]) %>%\n  select(sadt = y, consulta = x)\n#### Inclusão de valores previstos __------------------------    \ncai_SCc_Hil <- add_predictions(cai_SCc_Hil,lmT_hil.SCc)\n#### Novo gráfico -------------------------------------------\nggplot(cai_SCc_Hil, aes(y = consulta)) +\n  geom_point(aes(x = sadt), color = \"dark blue\", alpha = 0.5, size = 3) +\n  geom_line(aes(x = pred),color = \"orange\", size = 1.2) +\n  labs(title = 'Dados e Modelo transformados pelo procedimento de Hildreth-Lu', \n       x = 'SADT Transformado', y = 'Consulta Transformada')\n```\n\n<p align=\"justify\">A vantagem do pacote *\"HoRM\"* sobre o pacote *\"Orcutt\"* é a geração de objeto de modelo linear padrão, o que facilita os diagnósticos básicos do \"R\".</p>\n\n```{r analise após segunda transformação, fig.height=7, fig.width=10}\n## Gráficos\n## (1) (2)\n## (3) (4)\npar(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))\n#### Validando modelo pelos gráficos padrão -----------------\nplot(lmT_hil.SCc)\n#### Retornando à configurção de plotagem com Gráfico Único -\npar(mfrow = c(1,1), oma = c(0, 0, 0, 0))\n#### Sumário do novo modelo ---------------------------------\nsummary(lmT_hil.SCc)\n#### Avaliar se intervalo de confiança de 99% inclui 0 ------\nconfint(lmT_hil.SCc, level=0.99)\n```\n\n<p align=\"justify\">O sumário do terceiro modelo também confirma a rejeição das hipóteses nulas (coeficientes iguais a zero), pelos testes $t$ e $F$, e apresentando o mesma explicação de **94,55%** da variação de SADT por consulta, pois o mesmo valor de ruído foi aplicado à segunda transformação a partir do cálculo realizado no procedimento da primeira transformação (Orcutt).</p>\n\n***\n## Outros Experimentos\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">Outras técnicas e visualizações foram aplicadas dentro do estudo, e estão representadas a seguir, com respectivos comentários:</p>\n\n```{r demais aspectos, fig.height=7, fig.width=10}\n#### Intervalos para os valores previstos, IC 95% -----------\nas.tibble(predict.lm(lmT_hil.SCc, level=0.95, interval = 'confidence'))\n\n#### Preparação/Gráfico de intervalos do modelo original ----\n\n#rm(SCc.CI)\n\nSCc.CI <- as.tibble(predict.lm(lm.cai_SCc, level=0.95, interval = 'confidence'))\nSCc.CI <- add_column(SCc.CI, rn = as.numeric(row.names(SCc.CI)))\ncai_SCc <- add_column(cai_SCc, rn = as.numeric(row.names(SCc.CI)))\n\n#### Intervalos pelo pacote plotrix -------------------------\nplotCI(SCc.CI$fit[1:6], ui = SCc.CI$upr[1:6], li = SCc.CI$lwr[1:6], ylab = NULL, xlab = NULL)\n\n#### Intervalos com apresentação melhorada pelo GGplot2 -----\nggplot(SCc.CI[25:65,], aes(x = rn, y = fit, col = fit)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymax = upr, ymin = lwr)) +\n  geom_line(color = \"light blue\", size = 0.4, alpha = 0.5) +\n  geom_point(data = cai_SCc[25:65,], aes(y = sadt),col = \"red\" , size = 1.5) +\n  theme_dark() +\n  scale_colour_gradient2(name=\"Variação em\\ntorno da média\", \n                        low = \"white\", \n                        mid = \"orange\",\n                        midpoint = 591713,\n                        high = \"white\") +\n  labs(title = 'Amostra de assertividade nas previsões', \n       x = 'Observações', y = 'Valor Previsto')\n\n#### Teste de distribuição T para média de SADT, IC 95% ----- \nt.test(cai_SCc$sadt, conf.level = 0.95)\n\n#### Teste de distribuição T para média do modelo, IC 95% --- \nt.test(fitted(lmT.SCc), conf.level = 0.95) #IC para modelo\n\n#### Intervalo para coeficientes do modelo original, IC 95% - \nconfint(lm.cai_SCc, level=0.95)\n\n#### Gráfico padrão de SADT e valores previstos  ------------\npar(mfrow = c(1,2), oma = c(0, 0, 1.1, 0))\nplot(cai_SCc$sadt, col = 'blue')\nplot(fitted(lmT.SCc), col = 'green')\n\n#### Histograma padrão para SADT e modelo  ------------------\nhist(cai_SCc$sadt, col = 'light blue')\nhist(fitted(lmT.SCc), col = 'light green')\npar(mfrow = c(1,1), oma = c(0, 0, 0, 0))\n\n#### Histograma para SADT e modelo pelo GGPlot2 -------------\nggplot(cai_SCc,aes(sadt)) +\n  stat_bin(aes(y =..density..,\n               fill = ..count..), \n           col = \"black\",\n           binwidth = 35000, \n           alpha = 0.8) +\n  geom_density(fill = \"red\",\n               color = \"orange\",\n               alpha = 0.11) +\n  scale_x_continuous(breaks = seq(200000, 800000, by = 100000)) +\n  scale_y_continuous(labels = NULL) +\n  labs(title = 'Histograma de SADT', x = 'SADT', y = 'Contagem') +\n  scale_fill_distiller(name = 'Observações',\n                       palette = 'YlGnBu',\n                       direction = 1)\n\nggplot(cai_SCc,aes(predT)) +\n  stat_bin(aes(y =..density..,\n               fill = ..count..), \n           col = \"black\",\n           binwidth = 35000, \n           alpha = 0.8) +\n  geom_density(fill = \"red\",\n               color = \"blue\",\n               alpha = 0.11) +\n  scale_x_continuous(breaks = seq(200000, 800000, by = 100000)) +\n  scale_y_continuous(labels = NULL) +\n  labs(title = 'Histograma de SADT Previsto pelo modelo', x = 'SADT Previsto', y = 'Contagem') +\n  scale_fill_distiller(name = 'Observações',\n                       palette = 'YlGn',\n                       direction = 1)\n\n#### Gráfico de Controle Estatístico de Processo ------------\nqcc.cai_SCc <- qcc(cai_SCc$sadt, type = 'xbar.one', newdata = fitted(lmT.SCc));qcc.cai_SCc\n\n#### Histograma e densidade com alvos para capacidade -------\nprocess.capability (qcc.cai_SCc, spec.limits=c(400000,700000))\n```\n***\n## Visualizações de Dados\n[Retorno para Conteúdo](#conteudo)\n\n<p align=\"justify\">Além de suas capacidades estatísticas, o potencial de utilização da ferramenta apenas para demonstração de resultados é muito elevado, pois quase todos os aspectos da área de desenho podem ser modificados, e o conceito de gráfico em camadas permite a acumulação e troca de estruturas que não são possíveis no MS Excel:</p>\n\n```{r gráfico de receita/despesa, fig.height=7, fig.width=10}\n#### Importação de dados e inclusão de coluna ---------------\nrec_des <- read_excel('Gráfico e Previsão 2017 2.xlsx')\nrec_des <- rec_des %>% add_column(Diff = rec_des$Despesa - rec_des$Receita);as.tibble(rec_des)\n\n#### Gráfico base -------------------------------------------\nGGrec_des <- ggplot(data = rec_des, aes(x = Ano)) + # Dados básicos e eixos comuns\n  # Barras de despesa\n  geom_col(aes(y = Despesa/1000000, fill = Diff/1000000), \n           width = 0.9,\n           alpha=0.4, \n           #stat = \"sum\",\n           col = \"black\",\n           size = 1) +\n  # Efeito gradiente para qualquer preenchimento usado na estética do gráfico\n  scale_fill_gradient(name=\"Delta entre Despesa\\ne Receita em Mil, 2011 - 2017\",  \n                      low = \"green\", \n                      high = \"red\", \n                      space = \"Lab\",\n                      guide = \"colourbar\") +\n  # Controle da quebra da escala no eixo X\n  scale_x_continuous(breaks = seq(2011, 2017, by = 1)) +\n  # Mudança de orientação do texto da legenda do eixo x\n  theme(axis.text.x = element_text(angle = 45, \n                                 vjust = 1, \n                                 size = 9, \n                                 hjust = 1)) +\n  # Tema geral da área do gráfico\n  theme_light() +\n  # Textos de eixos e Título  \n  labs(title = 'Média Mensal de Despesa X Receita', x = 'Anos', y = 'Despesa/Receita');GGrec_des\n\n#### Gráfico com adição de camada com coluna de receita -----\nGGrec_des + \n  # Controle da quebra da escala no eixo y\n  scale_y_continuous(breaks = seq(50, 180, by = 10)) +\n  # Barras de receita\n  geom_bar(aes(y = Receita/1000000),\n           width = 0.5, alpha=0.3,\n           fill = \"blue\",\n           stat = \"sum\",\n           size = 1)\n\n#### Gráfico com adição de camada com área de receita -------\nGGrec_des + \n  # Área de receita\n  geom_area(aes(y = Receita/1000000),\n            col = \"blue\",\n            size = 0.2,\n            alpha = 0.3) +\n  # Pontos para marcação da receita sobre a área\n  geom_point(aes(y = Receita/1000000, col = Diff/1000000),\n             size=3.8, shape=21, fill=\"white\") +\n  # Texto com valores\n  geom_text(aes(y = (Despesa/1000000) + 16,\n                label = format((Diff/1000000), digits = 2),\n                col = Diff/1000000), \n            size = 4) +\n  # Efeito gradiente para qualquer cor usada na estética do gráfico  \n  scale_colour_gradient(name=\"Valor do Delta\\nem Mil, 2011 - 2017\", \n                    low = \"blue\", \n                    high = \"orange\", \n                    space = \"Lab\",\n                    guide = \"colourbar\") +\n  # Controle da quebra da escala no eixo y\n  scale_y_continuous(breaks = seq(50, 180, by = 10)) +\n  # troca de eixos somente para apresentação\n  coord_flip()\n```\n\n***\n## Conclusão\n[Retorno para Conteúdo](#conteudo)\n\nA partir do estudo realizado foram confirmadas as seguintes premissas:\n\n<p align=\"justify\">- A plataforma de código aberto \"R\" para computação estatística constitui uma ferramenta profissional, flexível e com alto poder de aplicação, desde de funções inerentes até suas estruturas secundárias para manipulação de dados e apresentação gráfica. Empresas como <b>Google, Pfizer, Microsoft, Uber, Facebook, IBM, Ford, Novartis, Roche, New York Times</b> (esta última para para visualização de dados) já fazem uso em grande escala, contando com equipes dedicadas e especialistas, incluindo desenvolvimento personalizado da ferramenta.</p>\n\n<p align=\"justify\">- Os resultados encontrados no piloto estatístico de Consultas X Exames confirmam o forte relacionamento entre estes componentes, e seu modelo linear poderá trazer uma vantagem estratégica no relacionamento com prestadores, principalmente no controle de resultados do projeto de \"Banco de Consultas\".</p>\n\n<p align=\"justify\">Estas respostas apontam para grande valia de futuros trabalhos realizados em conjunto com equipes técnicas do Planserv, e podem alavancar decisões em diversas disciplinas relacionadas a informação, com grandes contribuições para suporte a decisão, identificação de padrões, diagnóstico de distorções e estratégia em geral.</p>\n\n***\n",
    "created" : 1500075351873.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1999453353",
    "id" : "CF7C2270",
    "lastKnownWriteTime" : 1500773856,
    "last_content_update" : 1500773856511,
    "path" : "~/Estudo_Componente_Geral/Componente 01.Rmd",
    "project_path" : "Componente 01.Rmd",
    "properties" : {
        "docOutlineSize" : "175",
        "docOutlineVisible" : "1",
        "ignored_words" : "align,justify,Pfizer,Uber,Novartis,Roche,New,Planserv,Ihaka,Gentleman,Auckland,Candle,br,RStudio,Tidyverse,Markdown,GGPlot,Durbin,Breusch,Godfrey,Cochrane,Orcutt,Hildreth,HoRM,Stata,Minitab,MSExcel,lm,sadt,rho\n",
        "last_setup_crc32" : "5B229E2C428b032c"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}