theme(axis.text.x = element_text(angle = 45,
vjust = 1,
size = 12,
hjust = 1),
axis.title.x = element_blank(),
axis.title.y = element_blank())+
guides(fill = guide_colorbar(barwidth = 1,
barheight = 7,
title.position = "bottom")) +
coord_fixed();GGcorC
#### Camada adicionada ao gráfico original ------------------
GGcorC +
geom_text(aes(Var2, Var1, label = format(value, digits = 1, nsmall= 3)),
color = "black",
size = 3) +
scale_fill_distiller(palette = "Spectral",
#trans = "reverse",
#space = "Lab",
name="Correlação de\nPearson\n|Total|")
f.cor_plot <- function(ds, plt, dirc, lab_leg, dig) {
GGcor <- ggplot(data = melt(ds, na.rm = TRUE), aes(Var2, Var1, fill = value)) +
geom_tile(color = "white") +
scale_fill_distiller(palette = plt,
direction = dirc,
name=lab_leg) +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45,
vjust = 1,
size = 12,
hjust = 1),
axis.title.x = element_blank(),
axis.title.y = element_blank())+
guides(fill = guide_colorbar(barwidth = 1,
barheight = 7,
title.position = "bottom")) +
coord_fixed()
GGcor +
geom_text(aes(Var2, Var1, label = format(value, digits = dig, nsmall= 3)),
color = "black",
size = 3)
}
f.cor_plot(caiN.corP,"RdYlGn", 1,"Correlação de\nPearson\n|Ambulatório|",1)
f.cor_plot(caiS.corP,"Set2", -1,"Correlação de\nPearson\n|Internação|",2)
#### Tabela criada manualmente para simplificação de nomes --
(depara_componente <- read_excel('depara_componente.xlsx'))
#### Renomeação/substituição/exclusão de colunas (estudo) ---
depara_componente <- depara_componente %>%
select(componente = "Componente assistencial", comp = "componente")
#### Importações (Geradas pelo Power BI com um click) -------
`dataset` = read.csv('~/REditorWrapper_e74c054e-473b-47b7-b164-7b93f69f36af/input_df_0ab2289d-603e-43e7-9cef-461c578edbbb.csv', check.names = FALSE, encoding = "UTF-8", blank.lines.skip = FALSE);
## Opções iniciais de configuração do ambiente --------------
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
#### --------------------------------------------------------
library("reshape2", lib.loc="~/R/win-library/3.4")
library("readxl", lib.loc="~/R/win-library/3.4")
library("qcc", lib.loc="~/R/win-library/3.4")
library("modelr", lib.loc="~/R/win-library/3.4")
library("dplyr", lib.loc="~/R/win-library/3.4")
library("ggplot2", lib.loc="~/R/win-library/3.4")
library("readr", lib.loc="~/R/win-library/3.4")
library("tibble", lib.loc="~/R/win-library/3.4")
library("tidyr", lib.loc="~/R/win-library/3.4")
library("purrr", lib.loc="~/R/win-library/3.4")
library("forcats", lib.loc="~/R/win-library/3.4")
library("plotrix", lib.loc="~/R/win-library/3.4")
library("stringr", lib.loc="~/R/win-library/3.4")
## ** Pacotes básicos que compõe o Tidyverse poderiam ser ativados com uma unica linha:
#library("tidyverse", lib.loc="~/R/win-library/3.4"")
#Loading tidyverse: ggplot2
#Loading tidyverse: tibble
#Loading tidyverse: tidyr
#Loading tidyverse: readr
#Loading tidyverse: purrr
#Loading tidyverse: dplyr
#### Formato original, trabalhado no MS Excel ---------------
cat("Formato original, trabalhado no MS Excel")
org <- read_excel('CAIv2.xlsx');org;
#### Formato para processamento estatístico -----------------
cat("Formato para processamento estatístico")
cai <- read_excel('CAIv2.xlsx') %>% # readxl: importação
group_by(componente,internacao,amq) %>% # dplyr: agrupamento
summarise(valor = sum(valor), qt = sum(quantidade)) %>% # dplyr: sumarização
select(-valor) %>% # dplyr: retirada de uma coluna
spread(componente,qt) %>% # tidyr: mudança de formato, de chave-valor para colunas
arrange(amq, internacao) %>%  # dplyr: reordenação
filter(amq>="20140101"); cai; # dplyr: seleção;
#### Transformações sobre dados da "CAI" com uma função -----
f.tab_cor <-  function(caidf,mtd) {
corP <- caidf %>%
group_by(amq) %>%
summarise(consulta = sum(consulta, na.rm = TRUE),
domiciliar = sum(domiciliar, na.rm = TRUE),
emergencia = sum(emergencia, na.rm = TRUE),
honorario = sum(honorario, na.rm = TRUE),
material = sum(material, na.rm = TRUE),
medicamento = sum(medicamento, na.rm = TRUE),
nulo = sum(nulo, na.rm = TRUE),
pacote = sum(pacote, na.rm = TRUE),
remocao = sum(remocao, na.rm = TRUE),
sadt = sum(sadt, na.rm = TRUE),
taxa = sum(taxa, na.rm = TRUE)) %>%
as.data.frame(.) %>%
select(-amq) %>%
as.tibble() %>%
cor(., method = mtd)
}
#### Filtragem e calculo com função criada acima ------------
caiC.corP <- cai %>%
arrange(amq, internacao) %>%
f.tab_cor(.,'pearson');as.tibble(caiC.corP)
#### Apenas a primeira tabela (^) será demonstrada ----------
caiN.corP <- cai %>%
filter(internacao == 'n') %>%
arrange(amq) %>%
f.tab_cor(.,'pearson')
caiS.corP <- cai %>%
filter(internacao == 's') %>%
arrange(amq) %>%
f.tab_cor(.,'pearson')
#### Limpeza de objetos, caso necessário para recriação -----
rm(caiC.cor,caiS.cor,caiN.cor)
#### Representação por simbolos -----------------------------
Ccorgrid <- symnum(caiC.corP);Ccorgrid
#### Apenas a primeira tabela (^) será demonstrada ----------
Ncorgrid <- symnum(caiN.corP);#Ncorgrid
Scorgrid <- symnum(caiS.corP);#Scorgrid
#### Tratamento para apresentação gráfica -------------------
caiC.corP[lower.tri(caiC.corP)] <- NA
caiN.corP[lower.tri(caiN.corP)] <- NA
caiS.corP[lower.tri(caiS.corP)] <- NA
#### Gráfico gerado a partir do comando abaixo (exemplo) ----
GGcorC <- ggplot(data = melt(caiC.corP, na.rm = TRUE), aes(Var2, Var1, fill = value)) +
geom_tile(color = "white") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45,
vjust = 1,
size = 12,
hjust = 1),
axis.title.x = element_blank(),
axis.title.y = element_blank())+
guides(fill = guide_colorbar(barwidth = 1,
barheight = 7,
title.position = "bottom")) +
coord_fixed();GGcorC
#### Camada adicionada ao gráfico original ------------------
GGcorC +
geom_text(aes(Var2, Var1, label = format(value, digits = 1, nsmall= 3)),
color = "black",
size = 3) +
scale_fill_distiller(palette = "Spectral",
#trans = "reverse",
#space = "Lab",
name="Correlação de\nPearson\n|Total|")
f.cor_plot <- function(ds, plt, dirc, lab_leg, dig) {
GGcor <- ggplot(data = melt(ds, na.rm = TRUE), aes(Var2, Var1, fill = value)) +
geom_tile(color = "white") +
scale_fill_distiller(palette = plt,
direction = dirc,
name=lab_leg) +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45,
vjust = 1,
size = 12,
hjust = 1),
axis.title.x = element_blank(),
axis.title.y = element_blank())+
guides(fill = guide_colorbar(barwidth = 1,
barheight = 7,
title.position = "bottom")) +
coord_fixed()
GGcor +
geom_text(aes(Var2, Var1, label = format(value, digits = dig, nsmall= 3)),
color = "black",
size = 3)
}
f.cor_plot(caiN.corP,"RdYlGn", 1,"Correlação de\nPearson\n|Ambulatório|",1)
f.cor_plot(caiS.corP,"Set2", -1,"Correlação de\nPearson\n|Internação|",2)
#### Tabela criada manualmente para simplificação de nomes --
(depara_componente <- read_excel('depara_componente.xlsx'))
#### Renomeação/substituição/exclusão de colunas (estudo) ---
depara_componente <- depara_componente %>%
select(componente = "Componente assistencial", comp = "componente")
#### Importações (Geradas pelo Power BI com um click) -------
`dataset` = read.csv('~/REditorWrapper_e74c054e-473b-47b7-b164-7b93f69f36af/input_df_0ab2289d-603e-43e7-9cef-461c578edbbb.csv', check.names = FALSE, encoding = "UTF-8", blank.lines.skip = FALSE);
`dataset2` = read.csv('~/REditorWrapper_6b9a785a-59bf-48ad-abdd-04471637f315/input_df_26cec917-4b9e-45bf-9a31-7a50e9d1f2d7.csv', check.names = FALSE, encoding = "UTF-8", blank.lines.skip = FALSE);
#### Criação de resumos, por indicador de internação --------
f.resumo_valor <- function(ds) {
dsR <- ds %>%
select(internacao = "Indicador de Internação",
componente = "Componente assistencial",
valor = "Valor Total",
percentual =  "Valor Total.1",
quantidade = "Quantidade Aprovada") %>%
mutate(percentual = as.numeric(format(percentual*100, digits = 2))) %>%
merge(., depara_componente, by = "componente") %>%
mutate(componente = comp) %>%
select(-comp)
}
resumo_valor_N <- f.resumo_valor(dataset)
resumo_valor_S <- f.resumo_valor(dataset2)
#### Unificação de Tabelas-----------------------------------
resumo_valor <- rbind(resumo_valor_N,resumo_valor_S) %>%
arrange(internacao, desc(percentual)) %>%
select(-valor); resumo_valor
#### Transformação de tabela de correlação e filtro ---------
topcorS <- melt(caiS.corP, na.rm = TRUE) %>%
filter((value >= 0.85 | ((Var1 == "pacote" | Var2 == "pacote" |
Var1 == "medicamento" | Var2 == "medicamento" |
Var1 == "material" | Var2 == "material")
& value >= 0.70)) & value != 1) %>%
arrange(desc(value))
topcorN <- melt(caiN.corP, na.rm = TRUE) %>%
filter(value >= 0.85 & value != 1) %>%
arrange(desc(value))
#### Lookup de Tabelas e reordenação de colunas -------------
topcorS_W <- topcorS %>%
add_column(Var1_prct = resumo_valor_S[match(topcorS$Var1, resumo_valor_S$componente),4]) %>%
add_column(Var2_prct = resumo_valor_S[match(topcorS$Var2, resumo_valor_S$componente),4]) %>%
select("Var1","Var1_prct","Var2","Var2_prct",Corr = "value");topcorS_W
cat('^^ Internação ^^')
topcorN_W <- topcorN %>%
add_column(Var1_prct = resumo_valor_N[match(topcorN$Var1, resumo_valor_N$componente),4]) %>%
add_column(Var2_prct = resumo_valor_N[match(topcorN$Var2, resumo_valor_N$componente),4]) %>%
select("Var1","Var1_prct","Var2","Var2_prct",Corr = "value");topcorN_W
cat('^^ Ambulatório ^^')
#### Preparação: Transformação de tabela agrupada em plana --
cai_df <- cai %>%
as.data.frame() %>%
mutate(semestre = paste0(str_sub(amq,1,4),ifelse(str_sub(amq,5,6) > '06','02','01'))) %>%
as.tibble()
#### Função customizada para redução de passos --------------
f.sel_cai_var <- function(var_n, ind_int) {
cai_df %>%
filter(internacao == ind_int) %>%
arrange(amq) %>%
select(var_n) %>%
as.tibble()
}
#### Cor. Emergencia, Consulta > Taxas, Pacotes em Internação
cai_ECn_PTs.corP <- cbind(f.sel_cai_var(c('emergencia', 'consulta'), 'n'),
f.sel_cai_var(c('taxa', 'pacote'), 's')) %>%
.[1:77,] %>%
cor(., method = 'pearson');cai_ECn_PTs.corP
#### Preparação: Consulta sobre exames em Internação --------
cai_SCs <- cbind(f.sel_cai_var('sadt','s'), f.sel_cai_var('consulta','n'))
#### Preparação: Consulta sobre exames sem Internação -------
cai_SCn <- cbind(f.sel_cai_var('sadt','n'), f.sel_cai_var('consulta','n'))
#### Preparação: Consulta sobre exames totais ---------------
cai_SCc <- cai_df %>%
select(amq,sadt) %>%
group_by(amq) %>%
summarise(sadt=sum(sadt)) %>%
as.data.frame() %>%
select(sadt) %>%
as.tibble() %>%
add_column(consulta = f.sel_cai_var('consulta','n')$consulta)
## Inclusão de coluna "z", análise de variação por desvios padrão, outliers acima de 3
zSc <- scale(cai_SCc$sadt, center = TRUE, scale = TRUE)
cai_SCc <- cai_SCc %>% add_column(z = zSc[1:dim(cai_SCc)[1]])
cai_g <- cai_SCc %>%
select(consulta, sadt_t = sadt) %>%
add_column(sadt_n = cai_SCn$sadt) %>%
add_column(sadt_s = cai_SCs$sadt)
plot(cai_g)
#### Gerar objeto com modelo --------------------------------
f.lm_checkin <- function(ds, modl) {
lm.x <- lm(modl, data = ds)
print(summary(lm.x))
print(confint(lm.x, level=0.99))
for (i in c(1:3,5)) {
plot(lm.x, which = i)
}
return(lm.x)
}
## Gráficos
## (1) (2)
## (3) (4)
par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
lm.cai_SCc <- f.lm_checkin(cai_SCc, 'sadt ~ consulta')
#### Retornando à configurção de plotagem com Gráfico Único -
par(mfrow = c(1,1), oma = c(0, 0, 0, 0))
#### Incluir conluna com valores previstos ------------------
cai_SCc <- cai_SCc %>% add_predictions(lm.cai_SCc) #modelr
#### Gráfico do modelo --------------------------------------
ggplot(cai_SCc, aes(y = consulta)) +
geom_point(aes(x = sadt), color = "blue", alpha = 0.5, size = 3) +
geom_line(aes(x = pred),color = "red", size = 1.2) +
labs(title = 'Modelo proposto',
x = 'SADT', y = 'Consulta')
#### Definição do repositório para download -----------------
## options(repos = 'http://vps.fmvz.usp.br/CRAN/')
#### Instalação do novo pacote ------------------------------
## install.packages("lmtest")
#### Ativação do pacote com o teste estatístico -------------
library("lmtest", lib.loc="~/R/win-library/3.4")
#### Testes de autocorrelação -------------------------------
dwtest(lm.cai_SCc)
bgtest(lm.cai_SCc, order = 2)
#### Ativação do pacote com transformação para Autocorrelação
library("orcutt", lib.loc="~/R/win-library/3.4")
#### Transformação dos modelo para eliminação do ruído ------
lmT.SCc <- cochrane.orcutt(lm.cai_SCc)
#### Inclusão de coluna com valores previstos ajustados -----
cai_SCc <- cai_SCc %>% add_column(predT = as.vector(fitted(lmT.SCc))) #modelr
#### Novo gráfico, com ambos modelos ------------------------
ggplot(cai_SCc, aes(y = consulta)) +
geom_point(aes(x = sadt), color = "blue", alpha = 0.5, size = 3) +
geom_line(aes(x = pred),color = "red", size = 1.2) +
geom_line(aes(x = predT), color = "green", size = 1.2) +
labs(title = 'Modelo original e transformado, procedimento Cochrane Orcutt, *em verde',
x = 'SADT', y = 'Consulta')
summary.orcutt(lmT.SCc)
#### Valores previstos --------------------------------------
fit_r <- fitted(lmT.SCc)
#### Gráfico padrão (1) Linearidade -------------------------
plot(fit_r, resid(lmT.SCc),
ylab = "Resíduos/Erros",
xlab = "Valores Previstos",
main = "Linearidade e Variância")
#### Linha de referência ------------------------------------
smt = smooth.spline(fit_r, resid(lmT.SCc), spar=1)
abline(h = 0, lty = 2)
lines(smt, col='red', lwd=1)
#### Resíduos padronizados ----------------------------------
std_r <- resid(lmT.SCc)/sd(resid(lmT.SCc))
# ou std_r <- scale(resid(lmT.SCc), center = FALSE, scale = TRUE)
#### Gráfico padrão (2) Normalidade -------------------------
qqnorm(std_r)
#### Linha de referência ------------------------------------
qqline(std_r, lty = 2)
#### Raiz de resíduos padronizados --------------------------
std_r <- sqrt(abs(std_r))
#### Gráfico padrão (3) Igualdade ---------------------------
plot(fit_r, std_r,
ylab = expression(sqrt("Resíduos Padrão")),
xlab = "Valores Previstos",
main = "Escala e Localização de Resíduos")
#### Linha de referência ------------------------------------
smt = smooth.spline(fit_r, std_r, spar=1)
lines(smt, col='red', lwd=1)
#### Ativação do pacote com a segunda forma de transformação
library("HoRM", lib.loc="~/R/win-library/3.4")
#### Valor de rho a partir da primeira transformação --------
lmT.SCc["rho"]
#### Regressão com o novo procedimento ----------------------
lmT_hil.SCc <- hildreth.lu(x = cai_SCc$consulta, y = cai_SCc$sadt, rho = 0.7097007)
## rho representa o ruído gerado pela autocorrelação
#### Extração de dados a partir do objeto do modelo ---------
cai_SCc_Hil <- as.tibble(lmT_hil.SCc[["model"]]) %>%
select(sadt = y, consulta = x)
#### Inclusão de valores previstos __------------------------
cai_SCc_Hil <- add_predictions(cai_SCc_Hil,lmT_hil.SCc)
#### Novo gráfico -------------------------------------------
ggplot(cai_SCc_Hil, aes(y = consulta)) +
geom_point(aes(x = sadt), color = "dark blue", alpha = 0.5, size = 3) +
geom_line(aes(x = pred),color = "orange", size = 1.2) +
labs(title = 'Dados e Modelo transformados pelo procedimento de Hildreth-Lu',
x = 'SADT Transformado', y = 'Consulta Transformada')
#### Leitura do objeto do modelo ----------------------------
f.lm_extract <- function(lmo) {
print(summary(lmo))
print(confint(lmo, level=0.99))
for (i in c(1:3,5)) {
plot(lmo, which = i)
}
return(lmo)
}
## Gráficos
## (1) (2)
## (3) (4)
par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
invisible(f.lm_extract(lmT_hil.SCc))
#### Retornando à configurção de plotagem com Gráfico Único -
par(mfrow = c(1,1), oma = c(0, 0, 0, 0))
#### Intervalos para os valores previstos, IC 95% -----------
as.tibble(predict.lm(lmT_hil.SCc, level=0.95, interval = 'confidence'))
#### Preparação/Gráfico de intervalos do modelo original ----
#rm(SCc.CI)
SCc.CI <- as.tibble(predict.lm(lm.cai_SCc, level=0.95, interval = 'confidence')) %>%
add_column(., rn = as.numeric(row.names(.)))
cai_SCc <- add_column(cai_SCc, rn = as.numeric(row.names(SCc.CI)))
#### Intervalos pelo pacote plotrix -------------------------
plotCI(SCc.CI$fit[1:6], ui = SCc.CI$upr[1:6], li = SCc.CI$lwr[1:6], ylab = NULL, xlab = NULL)
#### Intervalos com apresentação melhorada pelo GGplot2 -----
ggplot(SCc.CI[25:65,], aes(x = rn, y = fit, col = fit)) +
geom_point(size = 2) +
geom_errorbar(aes(ymax = upr, ymin = lwr)) +
geom_line(color = "light blue", size = 0.4, alpha = 0.5) +
geom_point(data = cai_SCc[25:65,], aes(y = sadt),col = "red" , size = 1.5) +
theme_dark() +
scale_colour_gradient2(name="Variação em\ntorno da média",
low = "white",
mid = "orange",
midpoint = 591713,
high = "white") +
labs(title = 'Amostra de assertividade nas previsões',
x = 'Observações', y = 'Valor Previsto')
#### Teste de distribuição T para média de SADT, IC 95% -----
t.test(cai_SCc$sadt, conf.level = 0.95)
#### Teste de distribuição T para média do modelo, IC 95% ---
t.test(fitted(lmT.SCc), conf.level = 0.95) #IC para modelo
#### Intervalo para coeficientes do modelo original, IC 95% -
confint(lm.cai_SCc, level=0.95)
#### Gráfico padrão de SADT e valores previstos  ------------
par(mfrow = c(1,2), oma = c(0, 0, 1.1, 0))
plot(cai_SCc$sadt, col = 'blue')
plot(fitted(lmT.SCc), col = 'green')
#### Histograma padrão para SADT e modelo  ------------------
hist(cai_SCc$sadt, col = 'light blue')
hist(fitted(lmT.SCc), col = 'light green')
par(mfrow = c(1,1), oma = c(0, 0, 0, 0))
#### Histograma para SADT e modelo pelo GGPlot2 -------------
ggplot(cai_SCc,aes(sadt)) +
stat_bin(aes(y =..density..,
fill = ..count..),
col = "black",
binwidth = 35000,
alpha = 0.8) +
geom_density(fill = "red",
color = "orange",
alpha = 0.11) +
scale_x_continuous(breaks = seq(200000, 800000, by = 100000)) +
scale_y_continuous(labels = NULL) +
labs(title = 'Histograma de SADT', x = 'SADT', y = 'Contagem') +
scale_fill_distiller(name = 'Observações',
palette = 'YlGnBu',
direction = 1)
ggplot(cai_SCc,aes(predT)) +
stat_bin(aes(y =..density..,
fill = ..count..),
col = "black",
binwidth = 35000,
alpha = 0.8) +
geom_density(fill = "red",
color = "blue",
alpha = 0.11) +
scale_x_continuous(breaks = seq(200000, 800000, by = 100000)) +
scale_y_continuous(labels = NULL) +
labs(title = 'Histograma de SADT Previsto pelo modelo', x = 'SADT Previsto', y = 'Contagem') +
scale_fill_distiller(name = 'Observações',
palette = 'YlGn',
direction = 1)
#### Gráfico de Controle Estatístico de Processo ------------
qcc.cai_SCc <- qcc(cai_SCc$sadt, type = 'xbar.one', newdata = fitted(lmT.SCc));qcc.cai_SCc
#### Histograma e densidade com alvos para capacidade -------
process.capability (qcc.cai_SCc, spec.limits=c(400000,700000))
#### Importação de dados e inclusão de coluna ---------------
rec_des <- read_excel('Gráfico e Previsão 2017 2.xlsx') %>%
add_column(Diff = .$Despesa - .$Receita) %>%
as.tibble()
#### Gráfico base -------------------------------------------
GGrec_des <- ggplot(data = rec_des, aes(x = Ano)) + # Dados básicos e eixos comuns
# Barras de despesa
geom_col(aes(y = Despesa/1000000, fill = Diff/1000000),
width = 0.9,
alpha=0.4,
#stat = "sum",
col = "black",
size = 1) +
# Efeito gradiente para qualquer preenchimento usado na estética do gráfico
scale_fill_gradient(name="Delta entre Despesa\ne Receita em Mil, 2011 - 2017",
low = "green",
high = "red",
space = "Lab",
guide = "colourbar") +
# Controle da quebra da escala no eixo X
scale_x_continuous(breaks = seq(2011, 2017, by = 1)) +
# Tema geral da área do gráfico
theme_light() +
# Mudança de orientação do texto da legenda do eixo x
theme(axis.text.x = element_text(angle = 45,
vjust = 1,
size = 9,
hjust = 1)) +
# Textos de eixos e Título
labs(title = 'Média Mensal de Despesa X Receita', x = 'Anos', y = 'Despesa/Receita');GGrec_des
#### Gráfico com adição de camada com coluna de receita -----
GGrec_des +
# Controle da quebra da escala no eixo y
scale_y_continuous(breaks = seq(50, 180, by = 10)) +
# Barras de receita
geom_bar(aes(y = Receita/1000000),
width = 0.5, alpha=0.3,
fill = "blue",
stat = "sum",
size = 1)
#### Gráfico com adição de camada com área de receita -------
GGrec_des +
# Área de receita
geom_area(aes(y = Receita/1000000),
col = "blue",
size = 0.2,
alpha = 0.3) +
# Pontos para marcação da receita sobre a área
geom_point(aes(y = Receita/1000000, col = Diff/1000000),
size=3.8, shape=21, fill="white") +
# Texto com valores
geom_text(aes(y = (Despesa/1000000) + 13,
label = format((Diff/1000000), digits = 2),
col = Diff/1000000),
size = 4) +
# Efeito gradiente para qualquer cor usada na estética do gráfico
scale_colour_gradient(name="Valor do Delta\nem Mil, 2011 - 2017",
low = "blue",
high = "orange",
space = "Lab",
guide = "colourbar") +
# Controle da quebra da escala no eixo y
scale_y_continuous(breaks = seq(50, 180, by = 10)) +
# Zoom no eixo y
coord_cartesian(ylim=c(45,150))
