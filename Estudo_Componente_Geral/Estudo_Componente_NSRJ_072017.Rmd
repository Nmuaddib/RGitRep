---
output:
  html_document:
    code_folding: hide
    theme: cerulean
    highlight: pygments
---
<br><br>
![](banner.png)

***

## Objetivo
  
<p align="justify">**Apresentar estudo inicial realizado para dom?nio da plataforma de computa??o estat?stica "R". Os dados utilizados foram extra?dos a partir de BI (Banco de Intelig?ncia de Neg?cio) criado pela CTI em Fevereiro de 2017, sobre contas m?dicas e suas dimens?es, com uma s?rie temporal entre 2014 at? a ?ltima refer?ncia fechada e atualizada, em mar?o de 2017.**</p>

***
`ATEN??O`
<p align="justify">*O conte?do deste documento ? de natureza confidencial e n?o dever? ser circulado sem expressa autoriza??o da Coordena??o Geral do Planserv.*</p>

<p align="justify">*N?o ser? objetivo deste relat?rio tratar em detalhes as t?cnicas estat?sticas utilizadas, com exce??o de pontos relevantes para demonstrar a flexibilidade da ferramenta, como por exemplo a abordagem para verificar problemas de autocorrela??o em s?ries temporais. A teoria estat?stica envolvida, embora interessante para alguns p?blicos, tonaria o relato demasiado extenso.*</p>
***

##Conte?do

1. [Descri??o da Tecnologia](#descricao-da-tecnologia)  
2. [Introdu??o ao Estudo Proposto](#introducao-ao-estudo-proposto)  
3. [An?lise de Correla??o](#analise-de-correlacao)  
4. [Gr?ficos para Comunica??o](#graficos-para-comunicacao)  
5. [Direcionamento no Estudo](#direcionamento-no-estudo)  
6. [An?lise Detalhada sobre Consulta e Exames](#analise-detalhada-sobre-consulta-e-exames)  
6.1 [Prepara??o](#preparacao)  
6.2 [Sele??o de Escopo pelo Indicador de Interna??o](#selecao-de-escopo-pelo-indicador-de-internacao)  
7. [Regress?o Linear](#regressao-linear)  
7.1 [Modelo Inicial](#modelo-inicial)  
7.2 [Aspectos e Avalia??o da Regress?o](#aspectos-e-avaliacao-da-regressao)  
7.3 [Considera??es sobre S?ries Temporais](#consideracoes-sobre-series-temporais)  
7.4 [Avalia??o Espec?fica para Objetos do Pacote "Orcutt"](#avaliacao-especifica-para-objetos-do-pacote-orcutt)  
7.5 [Alternativa de Transforma??o](#alternativa-de-transformacao)  
8. [Outros Experimentos](#outros-experimentos)  
9. [Visualiza??es de Dados](#visualizacoes-de-dados)  
10. [Conclus?o](#conclusao)  

***
## Descri??o da Tecnologia
[Retorno para Conte?do](#conteudo)

<p align="justify">A ferramenta foi criada em 1992, por Ross Ihaka e Robert Gentleman, professores de estat?stica na Universidade de Auckland, Nova Zel?ndia, como um desenvolvimento comunit?rio de fonte livre (gratuito) sobre a linguagem "S", n?cleo fundamental da plataforma estat?stica S-Plus, comercializada.</p> 

<p align="justify">"R" pode ser descrita como uma linguagem de programa??o interpretativa (n?o ? necess?rio compilar seus scripts), possui integra??o com sistemas de gerenciamento de bancos de dados, outras linguagens (como Python), outras plataformas estat?sticas (importa??es de SPSS, SAS, Stata, Minitab), MSExcel e arquivos planos.</p>

<p align="justify">Desde sua cria??o, seu conte?do b?sico foi extensamente ampliado pela comunidade por meio da constru??o de pacotes que podem facilmente ser anexados ao ambiente b?sico, e que ampliam as funcionalidades da ferramenta contemplando a maioria das pr?ticas estat?sticas conhecidas, estilos e ferramentas para apresenta??es gr?ficas, manipula??o de dados, controles de qualidade, fun??es para facilitar e simplificar o desenvolvimento de seu c?digo, entre outras.</p>

<p align="justify">Como exemplo do funcionamento desta estrutura modular, abaixo est?o os pacotes que foram utilizados no estudo, contendo cada um v?rias das fun??es aplicadas na gera??o dos resultados demonstrados abaixo:</p>

```{r setup, message = FALSE, warning = FALSE}
## Op??es iniciais de configura??o do ambiente --------------
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
#### --------------------------------------------------------
library("stringr", lib.loc="~/R/win-library/3.4")
library("dplyr", lib.loc="~/R/win-library/3.4")
library("ggplot2", lib.loc="~/R/win-library/3.4")
library("readr", lib.loc="~/R/win-library/3.4")
library("tibble", lib.loc="~/R/win-library/3.4")
library("tidyr", lib.loc="~/R/win-library/3.4")
library("reshape2", lib.loc="~/R/win-library/3.4")
library("magrittr", lib.loc="~/R/win-library/3.4")
library("readxl", lib.loc="~/R/win-library/3.4")
library("modelr", lib.loc="~/R/win-library/3.4")
library("purrr", lib.loc="~/R/win-library/3.4")
library("forcats", lib.loc="~/R/win-library/3.4")
library("plotrix", lib.loc="~/R/win-library/3.4")
library("qcc", lib.loc="~/R/win-library/3.4")
## ** Pacotes b?sicos que comp?e o Tidyverse poderiam ser ativados com uma unica linha:
#library("tidyverse", lib.loc="~/R/win-library/3.4"")
#Loading tidyverse: ggplot2
#Loading tidyverse: tibble
#Loading tidyverse: tidyr
#Loading tidyverse: readr
#Loading tidyverse: purrr
#Loading tidyverse: dplyr
```

Vers?o da plataforma "R": 3.4.1 (2017-06-30) "Single Candle"<br>
<https://www.r-project.org/><br>
Vers?o do ambiente de programa??o "RStudio": 1.0.143<br>
<https://www.rstudio.com/><br>
Pacotes principais nesta apresenta??o: Tidyverse 1.1.1<br>
<http://tidyverse.org/><br>

<p align="justify">A apresenta??o deste relat?rio foi integralmente concebida com a utiliza??o do ambiente de programa??o RStudio, com a funcionalidade R-Markdown. <http://rmarkdown.rstudio.com/index.html></p>

![](rstudio.png)
<br><br>
<p align="right">*Ambiente de desenvolvimento integrado, RStutdio*</p>
***

<p align="justify">Para efeito demonstrativo, a maior parte dos comandos e fun??es utilizados para gera??o de resultados na ferramenta foi mantido ? vista, por?m a supress?o destes itens, mantendo apenas tabelas, coment?rios e gr?ficos ? facilmente executada dentro da estrutura RStudio + R-Markdown.</p>
***
## Introdu??o ao Estudo Proposto
[Retorno para Conte?do](#conteudo)

<p align="justify">O trabalho teve in?cio com dados gerados a partir da ferramenta Power BI e exportados para Excel, tratados e importados para o "R" de maneira n?o transformada (arquivo plano), e posteriormente tamb?m importados com transforma??es para processamento estat?stico (onde colunas = vari?veis). Os dados inclu?dos seguem as seguintes caracter?sticas:</p>

- S?rie temporal pela data de atendimento do componente assistencial;
- Duas consolida??es de quantidade por m?s de refer?ncia, uma entre dias 1 a 15 e outra entre 16 a 31, para aumento da efic?cia dos testes relacionados;
- Na transforma??o, foram filtrados dados de maior relev?ncia, a partir de janeiro de 2014, gerando 78 observa??es por componente;
- Dados de Componente, Ano/m?s/Quinzena e Indicador de Interna??o (CAI);

```{r dados originais}
#### Formato original, trabalhado no MS Excel ---------------
cat("Formato original, trabalhado no MS Excel")
org <- read_excel('CAIv2.xlsx');org;
#### Formato para processamento estat?stico -----------------
cat("Formato para processamento estat?stico")
cai <- read_excel('CAIv2.xlsx') %>% # readxl: importa??o
  group_by(componente,internacao,amq) %>% # dplyr: agrupamento
  summarise(valor = sum(valor), qt = sum(quantidade)) %>% # dplyr: sumariza??o
  select(-valor) %>% # dplyr: retirada de uma coluna
  spread(componente,qt) %>% # tidyr: mudan?a de formato, de chave-valor para colunas
  arrange(amq, internacao) %>%  # dplyr: reordena??o
  filter(amq>="20140101"); cai; # dplyr: sele??o;
```
***
## An?lise de Correla??o
[Retorno para Conte?do](#conteudo)

<p align="justify">A partir da tabela transformada acima, foi criada uma matriz de correla??o entre os componentes, para verifica??o de quais pares apresentavam influ?ncia sobre os demais. De modo a avaliar todas os relacionamentos, foram criadas tr?s vers?es: completo (C), sem interna??o(N) e com interna??o (S):</p>

```{r correla??o, warning=FALSE}
#### Transforma??es sobre dados da "CAI" com uma fun??o -----
f.tab_cor <-  function(caidf,mtd) {
  corP <- caidf %>%  
    group_by(amq) %>% 
    summarise(consulta = sum(consulta, na.rm = TRUE), 
              domiciliar = sum(domiciliar, na.rm = TRUE), 
              emergencia = sum(emergencia, na.rm = TRUE), 
              honorario = sum(honorario, na.rm = TRUE), 
              material = sum(material, na.rm = TRUE), 
              medicamento = sum(medicamento, na.rm = TRUE), 
              nulo = sum(nulo, na.rm = TRUE), 
              pacote = sum(pacote, na.rm = TRUE), 
              remocao = sum(remocao, na.rm = TRUE), 
              sadt = sum(sadt, na.rm = TRUE), 
              taxa = sum(taxa, na.rm = TRUE)) %>% 
    as.data.frame(.) %>%
    select(-amq) %>% 
    as.tibble() %>% 
    cor(., method = mtd)
}

#### Filtragem e calculo com fun??o criada acima ------------
caiC.corP <- cai %>%
  arrange(amq, internacao) %>% 
  f.tab_cor(.,'pearson');as.tibble(caiC.corP)

#### Apenas a primeira tabela (^) ser? demonstrada ----------
caiN.corP <- cai %>%
  filter(internacao == 'n') %>% 
  arrange(amq) %>%
  f.tab_cor(.,'pearson')

caiS.corP <- cai %>%
  filter(internacao == 's') %>% 
  arrange(amq) %>% 
  f.tab_cor(.,'pearson')

#### Limpeza de objetos, caso necess?rio para recria??o -----
rm(caiC.cor,caiS.cor,caiN.cor)

#### Representa??o por simbolos -----------------------------
Ccorgrid <- symnum(caiC.corP);Ccorgrid

#### Apenas a primeira tabela (^) ser? demonstrada ----------
Ncorgrid <- symnum(caiN.corP);#Ncorgrid
Scorgrid <- symnum(caiS.corP);#Scorgrid

#### Tratamento para apresenta??o gr?fica -------------------
caiC.corP[lower.tri(caiC.corP)] <- NA
caiN.corP[lower.tri(caiN.corP)] <- NA
caiS.corP[lower.tri(caiS.corP)] <- NA
```
***
## Gr?ficos para Comunica??o
[Retorno para Conte?do](#conteudo)

<p align="justify">Embora suficientes para avalia??o estat?stica de profissionais, os instrumentos apresentados at? ent?o n?o s?o adequados para demonstra??o de resultados  e aprecia??o de p?blicos em geral (outras capacidades sobre visualiza??o ser?o tratadas ao final deste estudo, no t?pico anterior ? conclus?o).</p>
<p align="justify">Com objetivo de evoluir da an?lise para comunica??o, os dados de correla??o foram submetidos a manipula??o por um dos pacotes especialistas do "R" para apresenta??es gr?ficas (GGPlot2), foram ent?o gerados os mapas de correla??o com est?tica mais adequada:</p>

```{r plot correla??o 01, fig.height=7, fig.width=10}
#### Gr?fico gerado a partir do comando abaixo (exemplo) ----
GGcorC <- ggplot(data = melt(caiC.corP, na.rm = TRUE), aes(Var2, Var1, fill = value)) +
  geom_tile(color = "white") +
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, 
                                   vjust = 1, 
                                   size = 12, 
                                   hjust = 1),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())+
  guides(fill = guide_colorbar(barwidth = 1, 
                               barheight = 7,
                               title.position = "bottom")) +
  coord_fixed();GGcorC

#### Camada adicionada ao gr?fico original ------------------
GGcorC + 
  geom_text(aes(Var2, Var1, label = format(value, digits = 1, nsmall= 3)), 
            color = "black", 
            size = 3) +
  scale_fill_distiller(palette = "Spectral", 
                       #trans = "reverse",
                       #space = "Lab", 
                       name="Correla??o de\nPearson\n|Total|")

```

Demais gr?ficos (Correla??o de componentes com Interna??o = N,S), comandos do "R" para gera??o foram ocultados:

```{r plot correla??o 02, fig.height=7, fig.width=10}
f.cor_plot <- function(ds, plt, dirc, lab_leg, dig) {
  GGcor <- ggplot(data = melt(ds, na.rm = TRUE), aes(Var2, Var1, fill = value)) +
    geom_tile(color = "white") +
    scale_fill_distiller(palette = plt, 
                        direction = dirc,
                        name=lab_leg) +  
    theme_minimal()+ 
    theme(axis.text.x = element_text(angle = 45, 
                                    vjust = 1, 
                                    size = 12, 
                                    hjust = 1),
          axis.title.x = element_blank(),
          axis.title.y = element_blank())+
    guides(fill = guide_colorbar(barwidth = 1, 
                                barheight = 7,
                                title.position = "bottom")) +
    coord_fixed()
  GGcor + 
    geom_text(aes(Var2, Var1, label = format(value, digits = dig, nsmall= 3)), 
              color = "black", 
              size = 3)
}

f.cor_plot(caiN.corP,"RdYlGn", 1,"Correla??o de\nPearson\n|Ambulat?rio|",1)

f.cor_plot(caiS.corP,"Set2", -1,"Correla??o de\nPearson\n|Interna??o|",2)
```

***
## Direcionamento no Estudo
[Retorno para Conte?do](#conteudo)

<p align="justify">Ap?s verificadas as influ?ncias, se fez necess?ria uma sele??o para detalhamento investigativo, al?m de um entendimento sobre o sentido da correla??o. Deste modo foi realizada uma consulta pelo BI de Contas para verifica??o de quais componentes correlacionados se mostravam relevantes, por valor e percentual no faturamento acumulado entre 2014 e 2017:</p>

```{r avalia??o de relev?ncia}
#### Tabela criada manualmente para simplifica??o de nomes --
(depara_componente <- read_excel('depara_componente.xlsx'))

#### Renomea??o/substitui??o/exclus?o de colunas (estudo) ---
depara_componente <- depara_componente %>% 
  select(componente = "Componente assistencial", comp = "componente")

#### Importa??es (Geradas pelo Power BI com um click) -------
`dataset` = read.csv('~/REditorWrapper_e74c054e-473b-47b7-b164-7b93f69f36af/input_df_0ab2289d-603e-43e7-9cef-461c578edbbb.csv', check.names = FALSE, encoding = "UTF-8", blank.lines.skip = FALSE);
`dataset2` = read.csv('~/REditorWrapper_6b9a785a-59bf-48ad-abdd-04471637f315/input_df_26cec917-4b9e-45bf-9a31-7a50e9d1f2d7.csv', check.names = FALSE, encoding = "UTF-8", blank.lines.skip = FALSE);

#### Cria??o de resumos, por indicador de interna??o --------

f.resumo_valor <- function(ds) {
  dsR <- ds %>% 
  select(internacao = "Indicador de Interna??o", 
         componente = "Componente assistencial",
         valor = "Valor Total",
         percentual =  "Valor Total.1",
         quantidade = "Quantidade Aprovada") %>% 
  mutate(percentual = as.numeric(format(percentual*100, digits = 2))) %>% 
  merge(., depara_componente, by = "componente") %>% 
  mutate(componente = comp) %>% 
  select(-comp)
}

resumo_valor_N <- f.resumo_valor(dataset)

resumo_valor_S <- f.resumo_valor(dataset2)

#### Unifica??o de Tabelas-----------------------------------
resumo_valor <- rbind(resumo_valor_N,resumo_valor_S) %>% 
  arrange(internacao, desc(percentual)) %>% 
  select(-valor); resumo_valor
```

<p align="justify">Foram ent?o filtradas as maiores Correla??es, e agregado o valor como uma nova coluna, para correla??es com interna??o, e sem interna??o. Aten??o especial foi dada ao relacionamento de pacotes para interna??o = "S":</p>

```{r maiores correla??es}
#### Transforma??o de tabela de correla??o e filtro ---------
topcorS <- melt(caiS.corP, na.rm = TRUE) %>% 
  filter((value >= 0.85 | ((Var1 == "pacote" | Var2 == "pacote" |
                            Var1 == "medicamento" | Var2 == "medicamento" |
                            Var1 == "material" | Var2 == "material") 
                           & value >= 0.70)) & value != 1) %>% 
  arrange(desc(value))

topcorN <- melt(caiN.corP, na.rm = TRUE) %>% 
  filter(value >= 0.85 & value != 1) %>% 
  arrange(desc(value))

#### Lookup de Tabelas e reordena??o de colunas -------------
topcorS_W <- topcorS %>% 
  add_column(Var1_prct = resumo_valor_S[match(topcorS$Var1, resumo_valor_S$componente),4]) %>% 
  add_column(Var2_prct = resumo_valor_S[match(topcorS$Var2, resumo_valor_S$componente),4]) %>% 
  select("Var1","Var1_prct","Var2","Var2_prct",Corr = "value");topcorS_W
cat('^^ Interna??o ^^')

topcorN_W <- topcorN %>% 
  add_column(Var1_prct = resumo_valor_N[match(topcorN$Var1, resumo_valor_N$componente),4]) %>% 
  add_column(Var2_prct = resumo_valor_N[match(topcorN$Var2, resumo_valor_N$componente),4]) %>% 
  select("Var1","Var1_prct","Var2","Var2_prct",Corr = "value");topcorN_W
cat('^^ Ambulat?rio ^^')
```

<p align="justify">Devido ? relev?ncia de Taxas e Pacotes em interna??o, foram averiguadas as correla??es cruzadas (presumidamente altas) a partir de consultas e emerg?ncia, que s?o considerados como ambulatoriais.</p>

<p align="justify">Para fins de estudo, foram criadas tabelas separadas e individualizadas para a an?lise, por?m uma abordagem similar ?s tabelas de correla??o geral poderia ter sido utilizada, com menos processos intermedi?rios na ferramenta, e diminui??o de passos:</p>

```{r correlacao cruzada}
#### Prepara??o: Transforma??o de tabela agrupada em plana --
cai_df <- cai %>% 
  as.data.frame() %>% 
  mutate(semestre = paste0(str_sub(amq,1,4),ifelse(str_sub(amq,5,6) > '06','02','01'))) %>% 
  as.tibble()

#### Fun??o customizada para redu??o de passos --------------
f.sel_cai_var <- function(var_n, ind_int) {
  cai_df %>%
    filter(internacao == ind_int) %>% 
    arrange(amq) %>% 
    select(var_n) %>% 
    as.tibble()  
}

#### Cor. Emergencia, Consulta > Taxas, Pacotes em Interna??o
cai_ECn_PTs.corP <- cbind(f.sel_cai_var(c('emergencia', 'consulta'), 'n'),
                          f.sel_cai_var(c('taxa', 'pacote'), 's')) %>% 
  .[1:77,] %>% 
  cor(., method = 'pearson');cai_ECn_PTs.corP
```
![](mapa.png)<br>
<p align="right">*\* Mapeamento sujeito ? mudan?as*</p>

***
## An?lise Detalhada sobre Consulta e Exames
[Retorno para Conte?do](#conteudo)

### Prepara??o
[Retorno para Conte?do](#conteudo)

<p align="justify">Com base nas descobertas apontadas pela correla??o, e considerando o sentido de influ?ncia conhecido de consultas sobre exames, foi ent?o realizada uma investiga??o de cunho estat?stico inferencial, com t?cnicas mais relevantes para determina??o de um modelo preditivo, onde a vari?vel independente ? a quantidade de consultas, e a resposta ? a quantidade de exames. Tais analises dever?o ser realizadas sobre outros conte?dos e elementos, com diversos e adequados modelos de regress?o, e com maior detalhamento para efetividade e precis?o, como por exemplo, a quebra de consultas e exames de uma determinada especialidade m?dica.</p>

```{r prepara??o para SC}
#### Prepara??o: Consulta sobre exames em Interna??o --------

cai_SCs <- cbind(f.sel_cai_var('sadt','s'), f.sel_cai_var('consulta','n'))

#### Prepara??o: Consulta sobre exames sem Interna??o -------

cai_SCn <- cbind(f.sel_cai_var('sadt','n'), f.sel_cai_var('consulta','n'))

#### Prepara??o: Consulta sobre exames totais ---------------

cai_SCc <- cai_df %>% 
  select(amq,sadt) %>% 
  group_by(amq) %>% 
  summarise(sadt=sum(sadt)) %>% 
  as.data.frame() %>% 
  select(sadt) %>% 
  as.tibble() %>% 
  add_column(consulta = f.sel_cai_var('consulta','n')$consulta)

## Inclus?o de coluna "z", an?lise de varia??o por desvios padr?o, outliers acima de 3 
zSc <- scale(cai_SCc$sadt, center = TRUE, scale = TRUE)
cai_SCc <- cai_SCc %>% add_column(z = zSc[1:dim(cai_SCc)[1]])
```

### Sele??o de Escopo pelo Indicador de Interna??o
[Retorno para Conte?do](#conteudo)

<p align="justify">Tamb?m foi criada uma tabela para avalia??o de relev?ncia de SADT total, com e sem interna??o:</p>

```{r sadt total, N, S, fig.height=7, fig.width=10}
cai_g <- cai_SCc %>% 
  select(consulta, sadt_t = sadt) %>% 
  add_column(sadt_n = cai_SCn$sadt) %>% 
  add_column(sadt_s = cai_SCs$sadt)

plot(cai_g)
```

<p align="justify">A matriz de gr?ficos de dispers?o indicou uma forte semelhan?a de comportamento entre **Consulta Eletiva sobre SADT total**, e **Consulta Eletiva sobre SADT sem interna??o (ambulatorial)**. Tamb?m pode ser verificado que **Consulta Eletiva sobre SADT com interna??o (hospitalar)** apresenta uma rela??o mais difusa, pois exames restritos ao ambiente hospitalar geralmente s?o disparados por outros componentes, fato que poderia ser comprovado com uma analise de correla??o espec?fica, caso a resposta gr?fica n?o fosse suficiente. Com base nos resultados, o estudo foi ent?o direcionado para modelo entre **Consulta e SADT total**.</p>
***
## Regress?o Linear
[Retorno para Conte?do](#conteudo)

### Modelo Inicial
[Retorno para Conte?do](#conteudo)

<p align="justify">Ap?s determina??o das vari?veis de estudo, a cria??o do modelo ? bastante simplificada pela ferramenta, atrav?s da fun??o lm (Linear Model), onde "sadt ~ consulta" representa uma equa??o de previs?o de quantidades de sadt por meio da informa??o de quantidades de consulta:</p>

```{r regress?o, fig.height=7, fig.width=10}
#### Gerar objeto com modelo --------------------------------
f.lm_checkin <- function(ds, modl) {
  lm.x <- lm(modl, data = ds)
  print(summary(lm.x))
  print(confint(lm.x, level=0.99))
  for (i in c(1:3,5)) {
    plot(lm.x, which = i)
  }
  return(lm.x)
}
## Gr?ficos
## (1) (2)
## (3) (4)
par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
lm.cai_SCc <- f.lm_checkin(cai_SCc, 'sadt ~ consulta')
#### Retornando ? configur??o de plotagem com Gr?fico ?nico -
par(mfrow = c(1,1), oma = c(0, 0, 0, 0))
```
Formula:

<p align="left"><font size="3" color="brown">$y = \beta_0 + \beta_1x$</font>, onde $\beta_0$ = intercepto e $\beta_1$ = inclina??o</p>
<p align="left"><font size="3" color="brown">$_{qt}sadt = \beta_0 + (\beta_1 * _{qt}consulta)$</font></p>
<p align="left"><font size="3" color="brown">$_{qt}sadt =   72791.6402 +  (11.6330 * _{qt}consulta)$</font></p>

<p align="justify">Apresentando valores de $p$ inferiores a **0,01** para ambos os coeficientes da equa??o e tamb?m para a estat?stica de varia??o $F$, a regress?o simples pode ser considerada de boa qualidade e suficiente, comprovando as tend?ncias previamente apontadas na correla??o. Caso necess?rio, modelos de outras naturezas poderiam ser aplicados na ferramenta (lineares m?ltiplos, quadr?ticos e n?o lineares, como polinomiais e exponenciais).</p>

<p align="justify">O valor do coeficiente de determina??o $r^2$ de **0.8948** significa que a quantidade de consultas explica **89,48%** da varia??o de quantidade de exames, e portanto o valor do modelo como instrumento preditivo aparenta ser relevante, inicialmente.</p>

<p align="justify">A fun??o padr?o de plotagem de gr?fico aplicada ao objeto do modelo na ferramenta, ? excelente para verifica??o r?pida de Linearidade (gr?fico 1, superior esquerdo), normalidade (gr?fico 2, superior direito) e Igualdade (gr?fico 3, inferior esquerdo), al?m de oferecer tamb?m um teste de alavancagem (gr?fico 4, inferior direito), que verifica se alguma observa??o extrema tem influ?ncia forte sobre todo o modelo.</p>

O modelo pode ser visualizado no gr?fico abaixo:

```{r, modelos inicial, fig.height=7, fig.width=10}
#### Incluir conluna com valores previstos ------------------
cai_SCc <- cai_SCc %>% add_predictions(lm.cai_SCc) #modelr
#### Gr?fico do modelo --------------------------------------
ggplot(cai_SCc, aes(y = consulta)) +
  geom_point(aes(x = sadt), color = "blue", alpha = 0.5, size = 3) +
  geom_line(aes(x = pred),color = "red", size = 1.2) +
  labs(title = 'Modelo proposto', 
       x = 'SADT', y = 'Consulta')
```

### Aspectos e Avalia??o da Regress?o
[Retorno para Conte?do](#conteudo)

<p align="justify">Embora as evid?ncias apontem para um modelo bem constru?do, existe ainda a necessidade de verificar todas as quatro premissas da regress?o: Linearidade (que pode ser verificada acima); Independ?ncia de vari?veis (de suma import?ncia no uso de s?ries temporais, devido ? possibilidade de Autocorrela??o: a ocorr?ncia de depend?ncia entre observa??es adjacentes no tempo), normalidade e Igualdade de vari?ncias para valores previstos (de SADT) ao longo de todos os valores de previs?o (consulta).</p>

### Considera??es sobre S?ries Temporais
[Retorno para Conte?do](#conteudo)

<p align="justify">No aspecto de independ?ncia das vari?veis, se faz necess?ria a utiliza??o de t?cnicas como os testes de **Durbin-Watson** ou **Breusch-Godfrey**, para verificar autocorrela??o. Uma vez identificada a t?cnica estat?stica desejada, uma consulta em sites de busca geralmente ? suficiente para apontar a fun??o e pacote correspondentes, estes podem ser adicionados de maneira simples por meio do ambiente RStudio, tornam-se dispon?veis para uso nos scripts.</p>

```{r teste de autocorrela??o, message=FALSE, warning=FALSE}
#### Defini??o do reposit?rio para download -----------------

## options(repos = 'http://vps.fmvz.usp.br/CRAN/')

#### Instala??o do novo pacote ------------------------------

## install.packages("lmtest")

#### Ativa??o do pacote com o teste estat?stico -------------
library("lmtest", lib.loc="~/R/win-library/3.4")
#### Testes de autocorrela??o -------------------------------
dwtest(lm.cai_SCc)
bgtest(lm.cai_SCc, order = 2)
```

<p align="justify">Ambos os testes apontam valor $p$ tendendo a zero, o que indica a rejei??o da hip?tese nula (que assume a Autocorrela??o = 0), e portanto uma transforma??o ? necess?ria, para enquadramento do princ?pio de independ?ncia de vari?veis. Novamente, uma vez identificada a t?cnica estat?stica (neste caso, transforma??o de **Cochrane Orcutt**), uma pesquisa ? feita, a fun??o e pacote s?o identificados, importados na ferramenta, e utilizados ap?s ativa??o. Em seguida encontra-se o gr?fico com ambos os modelos, original com autocorrela??o (em vermelho) e transformado, sem ru?dos ($rho$) de autocorrela??o (em verde):</p>

```{r transforma??o e gr?ficos, fig.height=7, fig.width=10}
#### Ativa??o do pacote com transforma??o para Autocorrela??o
library("orcutt", lib.loc="~/R/win-library/3.4")
#### Transforma??o dos modelo para elimina??o do ru?do ------
lmT.SCc <- cochrane.orcutt(lm.cai_SCc)
#### Inclus?o de coluna com valores previstos ajustados -----
cai_SCc <- cai_SCc %>% add_column(predT = as.vector(fitted(lmT.SCc))) #modelr
#### Novo gr?fico, com ambos modelos ------------------------
ggplot(cai_SCc, aes(y = consulta)) +
  geom_point(aes(x = sadt), color = "blue", alpha = 0.5, size = 3) +
  geom_line(aes(x = pred),color = "red", size = 1.2) +
  geom_line(aes(x = predT), color = "green", size = 1.2) +
  labs(title = 'Modelo original e transformado, procedimento Cochrane Orcutt, *em verde', 
       x = 'SADT', y = 'Consulta')
```

<p align="justify">Al?m da an?lise gr?fica, uma revis?o do sum?rio do novo modelo pode ser realizado com uma fun??o espec?fica do novo pacote:</p>

```{r an?lise ap?s transforma??o}
summary.orcutt(lmT.SCc)
```

Formula:

<p align="left"><font size="3" color="brown">$y = \beta_0 + \beta_1x$</font>, onde $\beta_0$ = intercepto e $\beta_1$ = inclina??o</p>
<p align="left"><font size="3" color="brown">$_{qt}sadt = \beta_0 + (\beta_1 * _{qt}consulta)$</font></p>
<p align="left"><font size="3" color="brown">$_{qt}sadt =  131162.26639 + (10.31995 * _{qt}consulta)$</font></p>

<p align="justify">Primeiramente, ? importante avaliar o resultado do teste de **Durbin Watson** para o modelo transformado, com valor pr?ximo ? **2**, e $p$ = **0.6253**, o que significa que n?o h? evid?ncias suficientes para rejeitar $h_0$ (*hip?tese nula*), onde a autocorrela??o ? igual a *zero*. O modelo ajustado revela as mesmas boas caracter?sticas, com valor $p$ para o teste $t$ dos coeficientes aproximadamente zero, assim como $p$ para a estat?stica de varia??o ($F$). O valor de $r^2$ dos novos resultados mostram que a vari?vel quantidade de consultas explica **94,55%** da varia??o de SADT, demonstrando a validade do novo modelo para predi??o.</p>

### Avalia??o Espec?fica para Objetos do Pacote "Orcutt"
[Retorno para Conte?do](#conteudo)

<p align="justify">Devido ? particularidade do pacote utilizado para a transforma??o (com objetos de modelo linear propriet?rios), uma an?lise dos aspectos da regress?o por fun??es padr?o da ferramenta ? limitada. Se faz necess?ria programa??o espec?fica para diagn?stico de linearidade, normalidade e igualdade de vari?ncias:</p>

Padroniza??o de res?duos:<font size="4" color="brown">$_{Std.}e = (\frac{e_i}{\sigma_e})_{1\leqslant i\leqslant n}$</font>,
onde <font size="3" color="brown">$\sigma = \sqrt\frac{\sum_{i=1}^n(X_i-\bar X)^2}{n-1}$</font>

```{r diagn?sticos constru?dos, fig.height=7, fig.width=10}
#### Valores previstos --------------------------------------
fit_r <- fitted(lmT.SCc)
#### Gr?fico padr?o (1) Linearidade -------------------------
plot(fit_r, resid(lmT.SCc),
     ylab = "Res?duos/Erros", 
     xlab = "Valores Previstos",
     main = "Linearidade e Vari?ncia")
#### Linha de refer?ncia ------------------------------------
smt = smooth.spline(fit_r, resid(lmT.SCc), spar=1)
abline(h = 0, lty = 2)
lines(smt, col='red', lwd=1)

#### Res?duos padronizados ----------------------------------
std_r <- resid(lmT.SCc)/sd(resid(lmT.SCc))
# ou std_r <- scale(resid(lmT.SCc), center = FALSE, scale = TRUE)

#### Gr?fico padr?o (2) Normalidade -------------------------
qqnorm(std_r)
#### Linha de refer?ncia ------------------------------------
qqline(std_r, lty = 2)

#### Raiz de res?duos padronizados --------------------------
std_r <- sqrt(abs(std_r))
#### Gr?fico padr?o (3) Igualdade ---------------------------
plot(fit_r, std_r, 
     ylab = expression(sqrt("Res?duos Padr?o")), 
     xlab = "Valores Previstos",
     main = "Escala e Localiza??o de Res?duos")
#### Linha de refer?ncia ------------------------------------
smt = smooth.spline(fit_r, std_r, spar=1)
lines(smt, col='red', lwd=1)
```

### Alternativa de Transforma??o
[Retorno para Conte?do](#conteudo)

<p align="justify">Uma alternativa de elimina??o dos ru?dos da autocorrela??o ? o procedimento de **Hildreth-Lu**, por?m esta abordagem exige aplica??o da transforma??o para todas as novas predi??es, pois existe uma altera??o da escala dos dados:</p>

```{r segunda transforma??o, fig.height=7, fig.width=10}
#### Ativa??o do pacote com a segunda forma de transforma??o
library("HoRM", lib.loc="~/R/win-library/3.4")
#### Valor de rho a partir da primeira transforma??o --------
lmT.SCc["rho"]
#### Regress?o com o novo procedimento ----------------------
lmT_hil.SCc <- hildreth.lu(x = cai_SCc$consulta, y = cai_SCc$sadt, rho = 0.7097007)
         ## rho representa o ru?do gerado pela autocorrela??o

#### Extra??o de dados a partir do objeto do modelo ---------
cai_SCc_Hil <- as.tibble(lmT_hil.SCc[["model"]]) %>%
  select(sadt = y, consulta = x)
#### Inclus?o de valores previstos __------------------------    
cai_SCc_Hil <- add_predictions(cai_SCc_Hil,lmT_hil.SCc)
#### Novo gr?fico -------------------------------------------
ggplot(cai_SCc_Hil, aes(y = consulta)) +
  geom_point(aes(x = sadt), color = "dark blue", alpha = 0.5, size = 3) +
  geom_line(aes(x = pred),color = "orange", size = 1.2) +
  labs(title = 'Dados e Modelo transformados pelo procedimento de Hildreth-Lu', 
       x = 'SADT Transformado', y = 'Consulta Transformada')
```

<p align="justify">A vantagem do pacote *"HoRM"* sobre o pacote *"Orcutt"* ? a gera??o de objeto de modelo linear padr?o, o que facilita os diagn?sticos b?sicos do "R".</p>

```{r analise ap?s segunda transforma??o, fig.height=7, fig.width=10}
#### Leitura do objeto do modelo ----------------------------
f.lm_extract <- function(lmo) {
  print(summary(lmo))
  print(confint(lmo, level=0.99))
  for (i in c(1:3,5)) {
    plot(lmo, which = i)
  }
  return(lmo)
}
## Gr?ficos
## (1) (2)
## (3) (4)
par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
invisible(f.lm_extract(lmT_hil.SCc))
#### Retornando ? configur??o de plotagem com Gr?fico ?nico -
par(mfrow = c(1,1), oma = c(0, 0, 0, 0))
```

<p align="justify">O sum?rio do terceiro modelo tamb?m confirma a rejei??o das hip?teses nulas (coeficientes iguais a zero), pelos testes $t$ e $F$, e apresentando o mesma explica??o de **94,55%** da varia??o de SADT por consulta, pois o mesmo valor de ru?do foi aplicado ? segunda transforma??o a partir do c?lculo realizado no procedimento da primeira transforma??o (Orcutt).</p>

***
## Outros Experimentos
[Retorno para Conte?do](#conteudo)

<p align="justify">Outras t?cnicas e visualiza??es foram aplicadas dentro do estudo, e est?o representadas a seguir, com respectivos coment?rios:</p>

```{r demais aspectos, fig.height=7, fig.width=10}
#### Intervalos para os valores previstos, IC 95% -----------
as.tibble(predict.lm(lmT_hil.SCc, level=0.95, interval = 'confidence'))

#### Prepara??o/Gr?fico de intervalos do modelo original ----

#rm(SCc.CI)

SCc.CI <- as.tibble(predict.lm(lm.cai_SCc, level=0.95, interval = 'confidence')) %>% 
  add_column(., rn = as.numeric(row.names(.)))
cai_SCc <- add_column(cai_SCc, rn = as.numeric(row.names(SCc.CI)))

#### Intervalos pelo pacote plotrix -------------------------
plotCI(SCc.CI$fit[1:6], ui = SCc.CI$upr[1:6], li = SCc.CI$lwr[1:6], ylab = NULL, xlab = NULL)

#### Intervalos com apresenta??o melhorada pelo GGplot2 -----
ggplot(SCc.CI[25:65,], aes(x = rn, y = fit, col = fit)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymax = upr, ymin = lwr)) +
  geom_line(color = "light blue", size = 0.4, alpha = 0.5) +
  geom_point(data = cai_SCc[25:65,], aes(y = sadt),col = "red" , size = 1.5) +
  theme_dark() +
  scale_colour_gradient2(name="Varia??o em\ntorno da m?dia", 
                        low = "white", 
                        mid = "orange",
                        midpoint = 591713,
                        high = "white") +
  labs(title = 'Amostra de assertividade nas previs?es', 
       x = 'Observa??es', y = 'Valor Previsto')

#### Teste de distribui??o T para m?dia de SADT, IC 95% ----- 
t.test(cai_SCc$sadt, conf.level = 0.95)

#### Teste de distribui??o T para m?dia do modelo, IC 95% --- 
t.test(fitted(lmT.SCc), conf.level = 0.95) #IC para modelo

#### Intervalo para coeficientes do modelo original, IC 95% - 
confint(lm.cai_SCc, level=0.95)

#### Gr?fico padr?o de SADT e valores previstos  ------------
par(mfrow = c(1,2), oma = c(0, 0, 1.1, 0))
plot(cai_SCc$sadt, col = 'blue')
plot(fitted(lmT.SCc), col = 'green')

#### Histograma padr?o para SADT e modelo  ------------------
hist(cai_SCc$sadt, col = 'light blue')
hist(fitted(lmT.SCc), col = 'light green')
par(mfrow = c(1,1), oma = c(0, 0, 0, 0))

#### Histograma para SADT e modelo pelo GGPlot2 -------------
ggplot(cai_SCc,aes(sadt)) +
  stat_bin(aes(y =..density..,
               fill = ..count..), 
           col = "black",
           binwidth = 35000, 
           alpha = 0.8) +
  geom_density(fill = "red",
               color = "orange",
               alpha = 0.11) +
  scale_x_continuous(breaks = seq(200000, 800000, by = 100000)) +
  scale_y_continuous(labels = NULL) +
  labs(title = 'Histograma de SADT', x = 'SADT', y = 'Contagem') +
  scale_fill_distiller(name = 'Observa??es',
                       palette = 'YlGnBu',
                       direction = 1)

ggplot(cai_SCc,aes(predT)) +
  stat_bin(aes(y =..density..,
               fill = ..count..), 
           col = "black",
           binwidth = 35000, 
           alpha = 0.8) +
  geom_density(fill = "red",
               color = "blue",
               alpha = 0.11) +
  scale_x_continuous(breaks = seq(200000, 800000, by = 100000)) +
  scale_y_continuous(labels = NULL) +
  labs(title = 'Histograma de SADT Previsto pelo modelo', x = 'SADT Previsto', y = 'Contagem') +
  scale_fill_distiller(name = 'Observa??es',
                       palette = 'YlGn',
                       direction = 1)

#### Gr?fico de Controle Estat?stico de Processo ------------
qcc.cai_SCc <- qcc(cai_SCc$sadt, type = 'xbar.one', newdata = fitted(lmT.SCc));qcc.cai_SCc

#### Histograma e densidade com alvos para capacidade -------
process.capability (qcc.cai_SCc, spec.limits=c(400000,700000))
```
***
## Visualiza??es de Dados
[Retorno para Conte?do](#conteudo)

<p align="justify">Al?m de suas capacidades estat?sticas, o potencial de utiliza??o da ferramenta apenas para demonstra??o de resultados ? muito elevado, pois quase todos os aspectos da ?rea de desenho podem ser modificados, e o conceito de gr?fico em camadas permite a acumula??o e troca de estruturas que n?o s?o poss?veis no MS Excel:</p>

```{r gr?fico de receita/despesa, fig.height=7, fig.width=10}
#### Importa??o de dados e inclus?o de coluna ---------------
rec_des <- read_excel('Gr?fico e Previs?o 2017 2.xlsx') %>%  
  add_column(Diff = .$Despesa - .$Receita) %>% 
  as.tibble()

#### Gr?fico base -------------------------------------------
GGrec_des <- ggplot(data = rec_des, aes(x = Ano)) + # Dados b?sicos e eixos comuns
  # Barras de despesa
  geom_col(aes(y = Despesa/1000000, fill = Diff/1000000), 
           width = 0.9,
           alpha=0.4, 
           #stat = "sum",
           col = "black",
           size = 1) +
  # Efeito gradiente para qualquer preenchimento usado na est?tica do gr?fico
  scale_fill_gradient(name="Delta entre Despesa\ne Receita em Mil, 2011 - 2017",  
                      low = "green", 
                      high = "red", 
                      space = "Lab",
                      guide = "colourbar") +
  # Controle da quebra da escala no eixo X
  scale_x_continuous(breaks = seq(2011, 2017, by = 1)) +
  # Tema geral da ?rea do gr?fico
  theme_light() +  
  # Mudan?a de orienta??o do texto da legenda do eixo x
  theme(axis.text.x = element_text(angle = 45, 
                                 vjust = 1, 
                                 size = 9, 
                                 hjust = 1)) +
  # Textos de eixos e T?tulo  
  labs(title = 'M?dia Mensal de Despesa X Receita', x = 'Anos', y = 'Despesa/Receita');GGrec_des

#### Gr?fico com adi??o de camada com coluna de receita -----
GGrec_des + 
  # Controle da quebra da escala no eixo y
  scale_y_continuous(breaks = seq(50, 180, by = 10)) +
  # Barras de receita
  geom_bar(aes(y = Receita/1000000),
           width = 0.5, alpha=0.3,
           fill = "blue",
           stat = "sum",
           size = 1)

#### Gr?fico com adi??o de camada com ?rea de receita -------
GGrec_des + 
  # ?rea de receita
  geom_area(aes(y = Receita/1000000),
            col = "blue",
            size = 0.2,
            alpha = 0.3) +
  # Pontos para marca??o da receita sobre a ?rea
  geom_point(aes(y = Receita/1000000, col = Diff/1000000),
             size=3.8, shape=21, fill="white") +
  # Texto com valores
  geom_text(aes(y = (Despesa/1000000) + 13,
                label = format((Diff/1000000), digits = 2),
                col = Diff/1000000), 
            size = 4) +
  # Efeito gradiente para qualquer cor usada na est?tica do gr?fico  
  scale_colour_gradient(name="Valor do Delta\nem Mil, 2011 - 2017", 
                    low = "blue", 
                    high = "orange", 
                    space = "Lab",
                    guide = "colourbar") +
  # Controle da quebra da escala no eixo y
  scale_y_continuous(breaks = seq(50, 180, by = 10)) +
  # Zoom no eixo y
  coord_cartesian(ylim=c(45,150))
```

***
## Conclus?o
[Retorno para Conte?do](#conteudo)

A partir do estudo realizado foram confirmadas as seguintes premissas:

<p align="justify">- A plataforma de c?digo aberto "R" para computa??o estat?stica constitui uma ferramenta profissional, flex?vel e com alto poder de aplica??o, desde de fun??es inerentes at? suas estruturas secund?rias para manipula??o de dados e apresenta??o gr?fica. Empresas como <b>Google, Pfizer, Microsoft, Uber, Facebook, IBM, Ford, Novartis, Roche, New York Times</b> (esta ?ltima para para visualiza??o de dados) j? fazem uso em grande escala, contando com equipes dedicadas e especialistas, incluindo desenvolvimento personalizado da ferramenta.</p>

<p align="justify">- Os resultados encontrados no piloto estat?stico de Consultas X Exames confirmam o forte relacionamento entre estes componentes, e seu modelo linear poder? trazer uma vantagem estrat?gica no relacionamento com prestadores, principalmente no controle de resultados do projeto de "Banco de Consultas".</p>

<p align="justify">Estas respostas apontam para grande valia de futuros trabalhos realizados em conjunto com equipes t?cnicas do Planserv, e podem alavancar decis?es em diversas disciplinas relacionadas a informa??o, com grandes contribui??es para suporte a decis?o, identifica??o de padr?es, diagn?stico de distor??es e estrat?gia em geral.</p>

***
